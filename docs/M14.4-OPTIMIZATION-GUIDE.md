# Phase 14 M14.4: Performance Optimization Guide

**Target**: Achieve >10x GPU speedup at 1K+ elements

## Current Implementation (Baseline)

Note on correctness (2025-11-13):

- CPU 参考已改为 BLS12-381 基域 Fq（6×u64 limbs），与 GLSL 模数保持一致。

- Shader 已加入越界保护：使用 `A.length()` 推导 elements，避免 dispatch 过量线程写越界导致数据被污染（尤其在 elements < local_size_x 时）。

**Architecture**:

- Host-visible, coherent buffers (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT)

- Synchronous CPU→GPU upload, GPU compute, GPU→CPU download

- Single command buffer submission per operation

- Workgroup size: 64 (hardcoded in shader)

**Bottlenecks**:
1. **PCIe Transfer**: Host-visible buffers require explicit sync
2. **Command Buffer Overhead**: Per-operation submission
3. **Fixed Workgroup Size**: Not tuned per GPU architecture

## Optimization Phases

### Phase 1: Device-Local Buffers + Staging (High Impact)

**Goal**: Reduce PCIe overhead by using GPU-local memory

**Changes**:

```rust
// Current: Host-visible
let props = vk::MemoryPropertyFlags::HOST_VISIBLE | HOST_COHERENT;

// Optimized: Device-local + staging
let device_props = vk::MemoryPropertyFlags::DEVICE_LOCAL;
let staging_props = vk::MemoryPropertyFlags::HOST_VISIBLE | HOST_COHERENT;

// Flow:
// 1. CPU write → staging buffer (host-visible)
// 2. Copy staging → device buffer (GPU-local, async)
// 3. Compute on device buffer
// 4. Copy device → staging (async)
// 5. CPU read ← staging buffer

```

**Expected Impact**: +20-40% for large batches (4K+ elements)

**Implementation**:

- Add `create_staging_buffer()` helper

- Implement `copy_buffer()` for buffer-to-buffer transfer

- Use pipeline barrier for sync (VK_PIPELINE_STAGE_TRANSFER → COMPUTE)

Runtime toggle (already wired):

- Set environment variable to enable device-local path without code changes:
    - Windows PowerShell: `$env:GPU_DEVICE_LOCAL = '1'`
    - Back to host-visible: `Remove-Item Env:GPU_DEVICE_LOCAL` or set to `0`

- The benchmark example and the public facade (`bls12_field_gpu::add_u64_limbs`) will respect this flag.

### Phase 2: Async Transfers + Pipelining (Medium Impact)

**Goal**: Overlap PCIe transfer with compute

**Changes**:

- Separate transfer and compute queues (if available)

- Use VkSemaphore for cross-queue sync

- Pipeline: Upload(N) | Compute(N-1) | Download(N-2)

**Expected Impact**: +10-20% for streaming workloads

**Complexity**: High (requires queue family management)

### Phase 3: Workgroup Size Specialization (Low-Medium Impact)

**Goal**: Tune workgroup size per GPU architecture

**Current**: `layout(local_size_x = 64)` hardcoded in shader

**Changes**:

- GLSL: Use specialization constants
  ```glsl
  layout(constant_id = 0) const uint WORKGROUP_SIZE = 64;
  layout(local_size_x = WORKGROUP_SIZE) in;
  ```

- Host: Provide specialization data via VkSpecializationInfo

- Runtime detection:
  - Small GPU (integrated): 32-64
  - Medium GPU (mobile): 64-128
  - Large GPU (desktop): 128-256

**Expected Impact**: +5-15% depending on GPU

### Phase 4: Batch Multiple Operations (High Impact for Small Ops)

**Goal**: Amortize command buffer overhead

**Changes**:

- Accept batch of operation pairs: `[(a1,b1), (a2,b2), ...]`

- Single command buffer with multiple dispatches

- Single submit for entire batch

**Expected Impact**: +50-100% for small operations (64-256 elements)

### Phase 5: Compute-Only Optimization (Low Impact)

**Goal**: Reduce ALU overhead in shader

**Shader Optimizations**:

- Loop unrolling (6 limbs → manual unroll)

- Reduction of conditional branches

- Manual vectorization (vec2/vec4 for adjacent limbs)

**Expected Impact**: +5-10%

## Profiling Tools

### Vulkan Validation Layers

```rust
// Enable in VkInstanceCreateInfo
let layer_names = [CString::new("VK_LAYER_KHRONOS_validation").unwrap()];

```

**Metrics**:

- Buffer memory usage

- Command buffer recording time

- Queue submit overhead

### RenderDoc (Optional)

- Frame capture for single dispatch

- Timeline view (upload → compute → download)

- Memory allocation visualization

### Manual Instrumentation

```rust
let upload_start = Instant::now();
// ... upload code ...
let upload_elapsed = upload_start.elapsed();

// Log: "Upload: {:.3}ms, Compute: {:.3}ms, Download: {:.3}ms"

```

## Implementation Priority

1. ✅ **Baseline Benchmark** (M14.4 Phase 1)
   - Measure current performance
   - Establish metrics

2. 🎯 **Device-Local Buffers** (M14.4 Phase 2 - HIGH PRIORITY)
   - Biggest potential gain
   - Moderate complexity
   - Foundation for async transfers

3. 🎯 **Workgroup Specialization** (M14.4 Phase 2 - MEDIUM PRIORITY)
   - Good ROI vs effort
   - Cross-platform benefit

4. 🔄 **Batch Operations** (M14.4 Phase 3 - CONDITIONAL)
   - Only if small-batch performance matters
   - API change required

5. 🔄 **Async Transfers** (M14.5 - FUTURE)
   - Complex, streaming-workload specific
   - Defer until clear use case

6. ⏸️ **Compute Optimization** (M14.5 - FUTURE)
   - Diminishing returns
   - Wait for profiling data

## Success Criteria

| Scale | Current (est.) | Target | Optimization |
|-------|---------------|--------|--------------|
| 64    | 1x            | 2x     | Batch ops |
| 1K    | 5x            | 10x    | Device-local |
| 4K    | 10x           | 20x    | Device-local + workgroup |
| 16K   | 15x           | 30x    | Device-local + async |
| 64K   | 20x           | 40x+   | All optimizations |

## Code Structure for Optimization

**Suggested Refactoring**:

```rust
// src/gpu-executor/src/spirv/vulkan_backend.rs

pub struct BufferConfig {
    pub use_device_local: bool,
    pub use_staging: bool,
    pub async_transfer: bool,
}

impl VulkanSpirvBackend {
    pub fn run_field_add_optimized(
        &self,
        spirv_bytes: &[u8],
        a: &[u64],
        b: &[u64],
        c_out: &mut Vec<u64>,
        elements: usize,
        config: BufferConfig,
    ) -> Result<(), VulkanError> {
        if config.use_device_local {
            self.run_with_device_local(...)
        } else {
            self.run_with_host_visible(...)  // current impl
        }
    }
}

```

This allows A/B testing different strategies with the same benchmark harness.
