# SuperVM å››å±‚ç½‘ç»œç¡¬ä»¶éƒ¨ç½²ä¸ç®—åŠ›è°ƒåº¦æ–¹æ¡ˆ

> **ä½œè€…**: KING XU (CHINA) | **åˆ›å»ºæ—¶é—´**: 2025-11-06

---

## ğŸ“‹ ç›®å½•

1. [æ ¸å¿ƒç†å¿µ](#æ ¸å¿ƒç†å¿µ)
2. [å››å±‚ç¡¬ä»¶è§„æ ¼](#å››å±‚ç¡¬ä»¶è§„æ ¼)
3. [å†…æ ¸å®‰è£…ä¸é€‚é…](#å†…æ ¸å®‰è£…ä¸é€‚é…)
4. [ä»»åŠ¡åˆ†å·¥æœºåˆ¶](#ä»»åŠ¡åˆ†å·¥æœºåˆ¶)
5. [å­˜å‚¨åˆ†å±‚ç®¡ç†](#å­˜å‚¨åˆ†å±‚ç®¡ç†)
6. [ç®—åŠ›è°ƒåº¦ç­–ç•¥](#ç®—åŠ›è°ƒåº¦ç­–ç•¥)
7. [**ç¥ç»ç½‘ç»œè·¯ç”±å¯»å€ç³»ç»Ÿ**](#ç¥ç»ç½‘ç»œè·¯ç”±å¯»å€ç³»ç»Ÿ) â­ **æœ€æ–°**
8. [å®æ–½è·¯çº¿å›¾](#å®æ–½è·¯çº¿å›¾)

---

## ğŸ¯ æ ¸å¿ƒç†å¿µ

### SuperVM åˆ†å¸ƒå¼æ¶æ„å“²å­¦

```
ä¼ ç»ŸåŒºå—é“¾:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ‰€æœ‰èŠ‚ç‚¹è¿è¡Œç›¸åŒè½¯ä»¶,æ‰§è¡Œç›¸åŒä»»åŠ¡
âŒ æµªè´¹èµ„æº (é«˜æ€§èƒ½æœåŠ¡å™¨åšç®€å•æŸ¥è¯¢)
âŒ æ— æ³•æ‰©å±• (å—é™äºæœ€å¼±èŠ‚ç‚¹)
âŒ æˆæœ¬é«˜æ˜‚ (æ‰€æœ‰èŠ‚ç‚¹éœ€é«˜ç«¯ç¡¬ä»¶)

SuperVM å››å±‚ç½‘ç»œ:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ ¹æ®ç¡¬ä»¶èƒ½åŠ›,è‡ªåŠ¨åˆ†é…ä¸åŒä»»åŠ¡
âœ… èµ„æºä¼˜åŒ– (å……åˆ†åˆ©ç”¨æ¯ä¸ªèŠ‚ç‚¹çš„èƒ½åŠ›)
âœ… æ°´å¹³æ‰©å±• (å¼±èŠ‚ç‚¹å¤„ç†ç®€å•ä»»åŠ¡)
âœ… æˆæœ¬é™ä½ (ä¸éœ€è¦æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯é«˜é…)
âœ… å…¨ç½‘ååŒ (ä»»åŠ¡è‡ªåŠ¨è·¯ç”±åˆ°åˆé€‚èŠ‚ç‚¹)
```

### è®¾è®¡åŸåˆ™

1. **ä¸€æ ¸å¤šæ€**: åŒä¸€ SuperVM å†…æ ¸,æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨è°ƒæ•´åŠŸèƒ½
2. **ä»»åŠ¡åˆ†å±‚**: å¤æ‚ä»»åŠ¡(å…±è¯†/ZK)â†’å¼ºèŠ‚ç‚¹,ç®€å•ä»»åŠ¡(æŸ¥è¯¢/è½¬å‘)â†’å¼±èŠ‚ç‚¹
3. **å­˜å‚¨åˆ†çº§**: å…¨é‡çŠ¶æ€â†’L1,éƒ¨åˆ†çŠ¶æ€â†’L2,çƒ­æ•°æ®â†’L3,æœ¬åœ°ç¼“å­˜â†’L4
4. **ç®—åŠ›æ± åŒ–**: æ‰€æœ‰èŠ‚ç‚¹è´¡çŒ®ç®—åŠ›,ç³»ç»Ÿæ™ºèƒ½è°ƒåº¦
5. **è‡ªåŠ¨é™çº§**: ç¡¬ä»¶ä¸è¶³æ—¶è‡ªåŠ¨é™çº§åŠŸèƒ½(å®Œæ•´èŠ‚ç‚¹â†’è½»èŠ‚ç‚¹)

---

## ğŸ–¥ï¸ å››å±‚ç¡¬ä»¶è§„æ ¼

### L1: è¶…ç®—èŠ‚ç‚¹ (Supercomputing Nodes)

**è§’è‰²**: å…±è¯†å‚ä¸è€…ã€å®Œæ•´çŠ¶æ€å­˜å‚¨ã€å¤æ‚è®¡ç®—

#### ç¡¬ä»¶è¦æ±‚

```yaml
æœ€ä½é…ç½®:
  CPU: 32 æ ¸å¿ƒ (Intel Xeon Silver / AMD EPYC)
  RAM: 128 GB DDR4
  å­˜å‚¨: 2 TB NVMe SSD (RocksDB)
  ç½‘ç»œ: 10 Gbps
  GPU: æ—  (å¯é€‰)

æ¨èé…ç½®:
  CPU: 64-128 æ ¸å¿ƒ (Intel Xeon Platinum / AMD EPYC 9654)
  RAM: 512 GB - 1 TB DDR5
  å­˜å‚¨: 10 TB NVMe SSD (RAID 0)
  ç½‘ç»œ: 25-100 Gbps
  GPU: NVIDIA H100 (å¯é€‰,ç”¨äº ZK åŠ é€Ÿ)

é«˜ç«¯é…ç½® (H200 8å¡):
  CPU: 2Ã— AMD EPYC 9654 (192 æ ¸å¿ƒ)
  RAM: 2 TB DDR5
  å­˜å‚¨: 100 TB NVMe SSD
  ç½‘ç»œ: 100 Gbps
  GPU: 8Ã— NVIDIA H200 (ç”¨äº ZK/AI)
```

#### å·¥ä½œè´Ÿè½½

```rust
// L1 èŠ‚ç‚¹ä¸»è¦ä»»åŠ¡
enum L1Task {
    Consensus,              // BFT å…±è¯†
    StateValidation,        // å®Œæ•´çŠ¶æ€éªŒè¯
    BlockProduction,        // åŒºå—ç”Ÿæˆ
    CrossShardSync,         // è·¨åˆ†ç‰‡åŒæ­¥
    ZkProofGeneration,      // ZK è¯æ˜ç”Ÿæˆ (å¯é€‰ GPU)
    ArchiveStorage,         // å†å²æ•°æ®å½’æ¡£
    ComplexQuery,           // å¤æ‚æŸ¥è¯¢ (èšåˆ/åˆ†æ)
}
```

#### é¢„æœŸæ€§èƒ½

```
TPS: 10-20K (å…±è¯†å—é™)
å­˜å‚¨: 10-100 TB å…¨é‡çŠ¶æ€
æŸ¥è¯¢å»¶è¿Ÿ: 10-50 ms
åŒºå—æ—¶é—´: 1-3 ç§’
ç½‘ç»œå¸¦å®½: 1-10 GB/s
ç®—åŠ›å ç”¨: 50-80% CPU
```

---

### L2: çŸ¿æœºèŠ‚ç‚¹ (Mining Nodes)

**è§’è‰²**: äº¤æ˜“æ‰§è¡Œã€åŒºå—æ‰“åŒ…ã€MVCC å¹¶è¡Œè°ƒåº¦

#### ç¡¬ä»¶è¦æ±‚

```yaml
æœ€ä½é…ç½®:
  CPU: 16 æ ¸å¿ƒ
  RAM: 64 GB
  å­˜å‚¨: 500 GB NVMe SSD
  ç½‘ç»œ: 1 Gbps
  GPU: æ— 

æ¨èé…ç½®:
  CPU: 32-64 æ ¸å¿ƒ (é«˜ä¸»é¢‘)
  RAM: 128-256 GB
  å­˜å‚¨: 2 TB NVMe SSD
  ç½‘ç»œ: 10 Gbps
  GPU: RTX 4090 (å¯é€‰,ç”¨äºå¯†ç å­¦)

ç‰¹æ®Šé…ç½® (æ¸¸æˆæœåŠ¡å™¨):
  CPU: 64 æ ¸å¿ƒ
  RAM: 512 GB
  å­˜å‚¨: 5 TB NVMe SSD
  ç½‘ç»œ: 25 Gbps
  GPU: RTX 4090 Ã— 2 (ç”¨äºæ¸¸æˆæ¸²æŸ“/AI)
```

#### å·¥ä½œè´Ÿè½½

```rust
// L2 èŠ‚ç‚¹ä¸»è¦ä»»åŠ¡
enum L2Task {
    TxExecution,            // äº¤æ˜“æ‰§è¡Œ (MVCC)
    TxValidation,           // äº¤æ˜“éªŒè¯
    MempoolManagement,      // äº¤æ˜“æ± ç®¡ç†
    BlockBuilding,          // åŒºå—æ„å»º
    StateUpdates,           // çŠ¶æ€æ›´æ–°
    EventEmission,          // äº‹ä»¶å‘é€
    LoadBalancing,          // è´Ÿè½½å‡è¡¡
    
    // æ¸¸æˆåœºæ™¯ä¸“ç”¨
    GameStateUpdate,        // æ¸¸æˆçŠ¶æ€æ›´æ–°
    PhysicsSimulation,      // ç‰©ç†æ¨¡æ‹Ÿ
    AIComputation,          // AI è®¡ç®—
}
```

#### é¢„æœŸæ€§èƒ½

```
TPS: 100-200K (MVCC å¹¶è¡Œ)
å­˜å‚¨: 500 GB - 2 TB (æœ€è¿‘çŠ¶æ€)
æŸ¥è¯¢å»¶è¿Ÿ: 1-5 ms
åŒºå—æ‰“åŒ…: < 100 ms
ç½‘ç»œå¸¦å®½: 100 MB - 1 GB/s
ç®—åŠ›å ç”¨: 70-90% CPU
```

---

### L3: è¾¹ç¼˜èŠ‚ç‚¹ (Edge Nodes)

**è§’è‰²**: åŒºåŸŸç¼“å­˜ã€äº¤æ˜“è½¬å‘ã€å¿«é€Ÿå“åº”

#### ç¡¬ä»¶è¦æ±‚

```yaml
æœ€ä½é…ç½®:
  CPU: 4 æ ¸å¿ƒ (ARM/x86)
  RAM: 8 GB
  å­˜å‚¨: 100 GB SSD
  ç½‘ç»œ: 100 Mbps
  GPU: æ— 

æ¨èé…ç½®:
  CPU: 8-16 æ ¸å¿ƒ
  RAM: 16-32 GB
  å­˜å‚¨: 256 GB SSD
  ç½‘ç»œ: 1 Gbps
  GPU: æ— 

è¾¹ç¼˜æœåŠ¡å™¨ (ä¼ä¸š/ISP):
  CPU: 16 æ ¸å¿ƒ
  RAM: 64 GB
  å­˜å‚¨: 1 TB SSD
  ç½‘ç»œ: 10 Gbps
  GPU: æ— 
```

#### å·¥ä½œè´Ÿè½½

```rust
// L3 èŠ‚ç‚¹ä¸»è¦ä»»åŠ¡
enum L3Task {
    RegionalCache,          // åŒºåŸŸç¼“å­˜ (LRU)
    TxRouting,              // äº¤æ˜“è·¯ç”±
    TxForwarding,           // äº¤æ˜“è½¬å‘
    QueryResponse,          // æŸ¥è¯¢å“åº”
    StateSync,              // çŠ¶æ€åŒæ­¥
    UserSession,            // ç”¨æˆ·ä¼šè¯ç®¡ç†
    
    // CDN åŠŸèƒ½
    AssetCaching,           // èµ„äº§ç¼“å­˜ (NFT/å›¾ç‰‡)
    ContentDelivery,        // å†…å®¹åˆ†å‘
}
```

#### é¢„æœŸæ€§èƒ½

```
TPS: 1M+ (ç¼“å­˜å‘½ä¸­)
å­˜å‚¨: 100 GB - 1 TB (çƒ­æ•°æ®)
æŸ¥è¯¢å»¶è¿Ÿ: < 10 ms
ç¼“å­˜å‘½ä¸­ç‡: 80-95%
ç½‘ç»œå¸¦å®½: 10-100 MB/s
ç®—åŠ›å ç”¨: 20-50% CPU
```

---

### L4: ç§»åŠ¨èŠ‚ç‚¹ (Mobile/IoT Nodes)

**è§’è‰²**: è½»å®¢æˆ·ç«¯ã€æœ¬åœ°ç¼“å­˜ã€å³æ—¶åé¦ˆã€**è½»é‡çº§è·¯ç”±å‚ä¸è€…** â­ æ–°å¢

#### ç¡¬ä»¶è¦æ±‚

```yaml
ç§»åŠ¨è®¾å¤‡ (æ‰‹æœº/å¹³æ¿):
  CPU: 4-8 æ ¸å¿ƒ (ARM)
  RAM: 4-8 GB
  å­˜å‚¨: 64-256 GB
  ç½‘ç»œ: 4G/5G/WiFi/è“ç‰™
  GPU: é›†æˆæ˜¾å¡
  è·¯ç”±ç¼“å­˜: 100-500 èŠ‚ç‚¹ (æ ¹æ®å†…å­˜åŠ¨æ€è°ƒæ•´)

IoT è®¾å¤‡:
  CPU: 1-2 æ ¸å¿ƒ (ARM Cortex)
  RAM: 512 MB - 2 GB
  å­˜å‚¨: 8-64 GB
  ç½‘ç»œ: WiFi/BLE/LoRa
  GPU: æ— 
  è·¯ç”±ç¼“å­˜: 50-100 èŠ‚ç‚¹ (æœ€å°é…ç½®)

æ¡Œé¢è½»èŠ‚ç‚¹:
  CPU: 4 æ ¸å¿ƒ
  RAM: 8 GB
  å­˜å‚¨: 100 GB
  ç½‘ç»œ: WiFi/æœ‰çº¿
  GPU: æ— 
  è·¯ç”±ç¼“å­˜: 200-500 èŠ‚ç‚¹ (è¾ƒå¥½é…ç½®)
```

#### å·¥ä½œè´Ÿè½½

```rust
// L4 èŠ‚ç‚¹ä¸»è¦ä»»åŠ¡
enum L4Task {
    LocalCache,             // æœ¬åœ°ç¼“å­˜
    TxSigning,              // äº¤æ˜“ç­¾å
    TxSubmission,           // äº¤æ˜“æäº¤
    BalanceQuery,           // ä½™é¢æŸ¥è¯¢
    EventListening,         // äº‹ä»¶ç›‘å¬
    
    // â­ æ–°å¢: è½»é‡çº§è·¯ç”±å‚ä¸
    RoutingCache,           // è·¯ç”±ç¼“å­˜ (100-500 èŠ‚ç‚¹)
    RouteRelay,             // è·¯ç”±ä¸­ç»§ (ä¸ºå…¶ä»– L4 æä¾›æŸ¥è¯¢)
    NatAssist,              // NAT ç©¿é€ååŠ© (å……å½“ STUN æœåŠ¡å™¨)
    LocalDiscovery,         // æœ¬åœ°å‘ç° (mDNS/è“ç‰™)
    
    // æ‰¹é‡æ“ä½œ
    OfflineQueue,           // ç¦»çº¿é˜Ÿåˆ—
    BatchSync,              // æ‰¹é‡åŒæ­¥
    
    // æ¸¸æˆå®¢æˆ·ç«¯
    LocalStatePredict,      // æœ¬åœ°çŠ¶æ€é¢„æµ‹
    AssetRendering,         // èµ„äº§æ¸²æŸ“
}
```

#### é¢„æœŸæ€§èƒ½

```
TPS: æœ¬åœ°æ“ä½œ (æ— é™åˆ¶)
å­˜å‚¨: 1-10 GB (ç”¨æˆ·æ•°æ®)
æŸ¥è¯¢å»¶è¿Ÿ: < 1 ms (æœ¬åœ°)
åŒæ­¥å‘¨æœŸ: 1-10 åˆ†é’Ÿ
ç½‘ç»œå¸¦å®½: 1-10 MB/s
ç®—åŠ›å ç”¨: 5-20% CPU
ç”µæ± å½±å“: æœ€å°åŒ–
```

---

## ğŸ”§ å†…æ ¸å®‰è£…ä¸é€‚é…

### ç»Ÿä¸€å†…æ ¸,å¤šé‡é…ç½®

**æ ¸å¿ƒç†å¿µ**: åŒä¸€ä¸ª SuperVM å†…æ ¸äºŒè¿›åˆ¶,æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨é€‚é…

```rust
// src/node-core/src/main.rs

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // 1. æ£€æµ‹ç¡¬ä»¶èƒ½åŠ›
    let hardware = HardwareDetector::detect()?;
    
    // 2. è‡ªåŠ¨å†³å®šèŠ‚ç‚¹ç±»å‹
    let node_type = NodeType::auto_detect(&hardware)?;
    
    // 3. åŠ è½½å¯¹åº”é…ç½®
    let config = Config::load_for_node_type(node_type)?;
    
    // 4. å¯åŠ¨èŠ‚ç‚¹
    let node = SuperVMNode::new(hardware, config)?;
    node.start().await?;
    
    Ok(())
}
```

### ç¡¬ä»¶æ£€æµ‹

```rust
// src/node-core/src/hardware_detector.rs

pub struct HardwareCapability {
    pub cpu_cores: usize,
    pub memory_gb: usize,
    pub disk_gb: usize,
    pub network_mbps: usize,
    pub has_gpu: bool,
    pub gpu_memory_gb: usize,
    pub arch: Architecture,  // x86_64, ARM64, ...
}

impl HardwareDetector {
    pub fn detect() -> Result<HardwareCapability> {
        let cpu_cores = num_cpus::get();
        let memory_gb = Self::detect_memory()?;
        let disk_gb = Self::detect_disk()?;
        let network_mbps = Self::detect_network()?;
        let (has_gpu, gpu_memory_gb) = Self::detect_gpu()?;
        let arch = Self::detect_arch();
        
        Ok(HardwareCapability {
            cpu_cores,
            memory_gb,
            disk_gb,
            network_mbps,
            has_gpu,
            gpu_memory_gb,
            arch,
        })
    }
    
    fn detect_memory() -> Result<usize> {
        #[cfg(target_os = "linux")]
        {
            // è¯»å– /proc/meminfo
            let content = std::fs::read_to_string("/proc/meminfo")?;
            // è§£æ MemTotal
            // ...
        }
        
        #[cfg(target_os = "windows")]
        {
            // ä½¿ç”¨ Windows API
            // ...
        }
        
        #[cfg(target_os = "macos")]
        {
            // ä½¿ç”¨ sysctl
            // ...
        }
    }
}
```

### èŠ‚ç‚¹ç±»å‹è‡ªåŠ¨å†³ç­–

```rust
// src/node-core/src/node_type.rs

#[derive(Debug, Clone, Copy)]
pub enum NodeType {
    L1Supernode,    // è¶…ç®—èŠ‚ç‚¹
    L2Miner,        // çŸ¿æœºèŠ‚ç‚¹
    L3Edge,         // è¾¹ç¼˜èŠ‚ç‚¹
    L4Mobile,       // ç§»åŠ¨èŠ‚ç‚¹
}

impl NodeType {
    pub fn auto_detect(hw: &HardwareCapability) -> Result<Self> {
        // å†³ç­–æ ‘ç®—æ³•
        if hw.cpu_cores >= 32 && hw.memory_gb >= 128 && hw.disk_gb >= 2000 {
            Ok(NodeType::L1Supernode)
        } else if hw.cpu_cores >= 16 && hw.memory_gb >= 64 && hw.disk_gb >= 500 {
            Ok(NodeType::L2Miner)
        } else if hw.cpu_cores >= 4 && hw.memory_gb >= 8 && hw.disk_gb >= 100 {
            Ok(NodeType::L3Edge)
        } else {
            Ok(NodeType::L4Mobile)
        }
    }
    
    /// æ‰‹åŠ¨æŒ‡å®šèŠ‚ç‚¹ç±»å‹ (å‘½ä»¤è¡Œå‚æ•°)
    pub fn from_str(s: &str) -> Result<Self> {
        match s {
            "l1" | "supernode" => Ok(NodeType::L1Supernode),
            "l2" | "miner" => Ok(NodeType::L2Miner),
            "l3" | "edge" => Ok(NodeType::L3Edge),
            "l4" | "mobile" => Ok(NodeType::L4Mobile),
            _ => Err(anyhow!("Unknown node type: {}", s)),
        }
    }
}
```

### é…ç½®æ–‡ä»¶ç»“æ„

```toml
# config/l1_supernode.toml

[node]
type = "L1Supernode"
name = "supernode-asia-01"
region = "Asia/Shanghai"

[hardware]
cpu_cores = 64
memory_gb = 512
disk_gb = 10000
network_mbps = 25000

[consensus]
enable = true
algorithm = "BFT"
validators = 100
block_time_ms = 2000

[storage]
backend = "RocksDB"
path = "/data/supervm/state"
cache_gb = 64
enable_pruning = false  # ä¿ç•™å®Œæ•´å†å²

[execution]
parallel = true
mvcc = true
max_tps = 20000

[network]
listen = "0.0.0.0:9000"
peers_l1 = ["supernode-us-01:9000", "supernode-eu-01:9000"]
peers_l2 = []  # ä¸ç›´æ¥è¿æ¥ L2
```

```toml
# config/l2_miner.toml

[node]
type = "L2Miner"
name = "miner-01"
region = "Asia/Shanghai"

[hardware]
cpu_cores = 32
memory_gb = 128
disk_gb = 2000

[consensus]
enable = false  # L2 ä¸å‚ä¸å…±è¯†

[storage]
backend = "RocksDB"
path = "/data/supervm/state"
cache_gb = 16
enable_pruning = true
prune_keep_blocks = 10000  # ä¿ç•™æœ€è¿‘ 10000 åŒºå—

[execution]
parallel = true
mvcc = true
max_tps = 200000

[network]
listen = "0.0.0.0:9001"
peers_l1 = ["supernode-asia-01:9000"]  # è¿æ¥åˆ° L1
peers_l2 = ["miner-02:9001", "miner-03:9001"]  # P2P ç½‘ç»œ
peers_l3 = []  # ç›‘å¬ L3 è¿æ¥
```

```toml
# config/l3_edge.toml

[node]
type = "L3Edge"
name = "edge-shanghai"
region = "Asia/Shanghai"

[hardware]
cpu_cores = 8
memory_gb = 16
disk_gb = 256

[consensus]
enable = false

[storage]
backend = "LRU"  # ä»…å†…å­˜ç¼“å­˜
cache_gb = 4
enable_pruning = true
prune_keep_blocks = 1000

[execution]
parallel = false  # L3 ä¸æ‰§è¡Œäº¤æ˜“,ä»…è½¬å‘
mvcc = false

[network]
listen = "0.0.0.0:9002"
peers_l2 = ["miner-01:9001"]  # è¿æ¥åˆ° L2
peers_l3 = ["edge-beijing:9002", "edge-guangzhou:9002"]
peers_l4 = []  # ç›‘å¬ L4 è¿æ¥

[cache]
strategy = "LRU"
max_entries = 100000
ttl_seconds = 3600
prefetch = true  # é¢„å–çƒ­ç‚¹æ•°æ®
```

```toml
# config/l4_mobile.toml

[node]
type = "L4Mobile"
name = "mobile-client"

[hardware]
cpu_cores = 4
memory_gb = 4
disk_gb = 10

[consensus]
enable = false

[storage]
backend = "SQLite"  # è½»é‡çº§æ•°æ®åº“
path = "./supervm.db"
cache_mb = 100

[execution]
parallel = false
mvcc = false

[network]
peers_l3 = ["edge-shanghai:9002"]  # ä»…è¿æ¥æœ€è¿‘çš„ L3
sync_interval_seconds = 60  # æ¯åˆ†é’ŸåŒæ­¥ä¸€æ¬¡
batch_size = 100  # æ‰¹é‡æ“ä½œ

[offline]
enable_queue = true
max_queue_size = 1000
```

### ä¸€é”®å®‰è£…è„šæœ¬

```bash
#!/bin/bash
# install.sh - SuperVM è‡ªåŠ¨å®‰è£…è„šæœ¬

echo "ğŸš€ SuperVM å®‰è£…å‘å¯¼"
echo "===================="

# 1. æ£€æµ‹æ“ä½œç³»ç»Ÿ
OS=$(uname -s)
ARCH=$(uname -m)
echo "æ£€æµ‹åˆ°ç³»ç»Ÿ: $OS $ARCH"

# 2. æ£€æµ‹ç¡¬ä»¶
CPU_CORES=$(nproc)
MEMORY_GB=$(($(free -g | awk '/^Mem:/{print $2}')))
DISK_GB=$(($(df -BG / | tail -1 | awk '{print $4}' | tr -d 'G')))

echo "ç¡¬ä»¶é…ç½®:"
echo "  CPU æ ¸å¿ƒ: $CPU_CORES"
echo "  å†…å­˜: ${MEMORY_GB} GB"
echo "  ç£ç›˜: ${DISK_GB} GB"

# 3. è‡ªåŠ¨æ¨èèŠ‚ç‚¹ç±»å‹
if [ $CPU_CORES -ge 32 ] && [ $MEMORY_GB -ge 128 ]; then
    RECOMMENDED="L1 è¶…ç®—èŠ‚ç‚¹"
    NODE_TYPE="l1"
elif [ $CPU_CORES -ge 16 ] && [ $MEMORY_GB -ge 64 ]; then
    RECOMMENDED="L2 çŸ¿æœºèŠ‚ç‚¹"
    NODE_TYPE="l2"
elif [ $CPU_CORES -ge 4 ] && [ $MEMORY_GB -ge 8 ]; then
    RECOMMENDED="L3 è¾¹ç¼˜èŠ‚ç‚¹"
    NODE_TYPE="l3"
else
    RECOMMENDED="L4 ç§»åŠ¨èŠ‚ç‚¹"
    NODE_TYPE="l4"
fi

echo ""
echo "æ¨èèŠ‚ç‚¹ç±»å‹: $RECOMMENDED"
read -p "æ˜¯å¦æ¥å—æ¨è? (Y/n): " ACCEPT

if [ "$ACCEPT" != "n" ]; then
    echo "å°†å®‰è£… $RECOMMENDED"
else
    echo "è¯·é€‰æ‹©èŠ‚ç‚¹ç±»å‹:"
    echo "  1) L1 è¶…ç®—èŠ‚ç‚¹"
    echo "  2) L2 çŸ¿æœºèŠ‚ç‚¹"
    echo "  3) L3 è¾¹ç¼˜èŠ‚ç‚¹"
    echo "  4) L4 ç§»åŠ¨èŠ‚ç‚¹"
    read -p "é€‰æ‹© (1-4): " CHOICE
    
    case $CHOICE in
        1) NODE_TYPE="l1" ;;
        2) NODE_TYPE="l2" ;;
        3) NODE_TYPE="l3" ;;
        4) NODE_TYPE="l4" ;;
        *) echo "æ— æ•ˆé€‰æ‹©"; exit 1 ;;
    esac
fi

# 4. ä¸‹è½½äºŒè¿›åˆ¶
echo ""
echo "ä¸‹è½½ SuperVM äºŒè¿›åˆ¶..."
DOWNLOAD_URL="https://github.com/XujueKing/SuperVM/releases/latest/download/supervm-${OS}-${ARCH}"
wget -O /usr/local/bin/supervm "$DOWNLOAD_URL"
chmod +x /usr/local/bin/supervm

# 5. ä¸‹è½½é…ç½®æ–‡ä»¶
echo "ä¸‹è½½é…ç½®æ–‡ä»¶..."
CONFIG_URL="https://github.com/XujueKing/SuperVM/releases/latest/download/config-${NODE_TYPE}.toml"
mkdir -p ~/.supervm
wget -O ~/.supervm/config.toml "$CONFIG_URL"

# 6. åˆå§‹åŒ–æ•°æ®ç›®å½•
echo "åˆå§‹åŒ–æ•°æ®ç›®å½•..."
mkdir -p ~/.supervm/data
mkdir -p ~/.supervm/logs

# 7. åˆ›å»º systemd æœåŠ¡ (Linux)
if [ "$OS" = "Linux" ]; then
    echo "åˆ›å»º systemd æœåŠ¡..."
    cat > /etc/systemd/system/supervm.service <<EOF
[Unit]
Description=SuperVM Node
After=network.target

[Service]
Type=simple
User=$USER
ExecStart=/usr/local/bin/supervm --config ~/.supervm/config.toml
Restart=on-failure
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

    systemctl daemon-reload
    systemctl enable supervm
    
    echo "å¯åŠ¨ SuperVM èŠ‚ç‚¹..."
    systemctl start supervm
    
    echo ""
    echo "âœ… å®‰è£…å®Œæˆ!"
    echo "æŸ¥çœ‹çŠ¶æ€: systemctl status supervm"
    echo "æŸ¥çœ‹æ—¥å¿—: journalctl -u supervm -f"
else
    echo ""
    echo "âœ… å®‰è£…å®Œæˆ!"
    echo "å¯åŠ¨èŠ‚ç‚¹: supervm --config ~/.supervm/config.toml"
fi
```

---

## ğŸ¯ ä»»åŠ¡åˆ†å·¥æœºåˆ¶

### æ™ºèƒ½ä»»åŠ¡è·¯ç”±

```rust
// src/node-core/src/task_router.rs

pub struct TaskRouter {
    local_capability: HardwareCapability,
    node_type: NodeType,
    peers: Vec<PeerNode>,
}

pub struct PeerNode {
    pub id: NodeId,
    pub node_type: NodeType,
    pub capability: HardwareCapability,
    pub load: f64,  // 0.0-1.0
    pub latency_ms: u64,
}

impl TaskRouter {
    /// å†³å®šä»»åŠ¡åº”è¯¥åœ¨å“ªé‡Œæ‰§è¡Œ
    pub async fn route_task(&self, task: Task) -> TaskDestination {
        match task {
            // æœ¬åœ°å¯å¤„ç†çš„ä»»åŠ¡
            Task::SimpleQuery(_) if self.can_handle_locally(&task) => {
                TaskDestination::Local
            }
            
            // éœ€è¦è½¬å‘åˆ°æ›´å¼ºèŠ‚ç‚¹
            Task::ZkProof(_) if self.node_type != NodeType::L1Supernode => {
                let best_l1 = self.find_best_peer(NodeType::L1Supernode);
                TaskDestination::Remote(best_l1)
            }
            
            // éœ€è¦åˆ†å¸ƒå¼æ‰§è¡Œ
            Task::LargeComputation(_) => {
                let workers = self.find_available_workers();
                TaskDestination::Distributed(workers)
            }
            
            _ => TaskDestination::Local,
        }
    }
    
    fn can_handle_locally(&self, task: &Task) -> bool {
        match (self.node_type, task) {
            (NodeType::L1Supernode, _) => true,  // L1 å¯å¤„ç†æ‰€æœ‰ä»»åŠ¡
            (NodeType::L2Miner, Task::TxExecution(_)) => true,
            (NodeType::L3Edge, Task::Query(_)) => true,
            (NodeType::L4Mobile, Task::LocalOp(_)) => true,
            _ => false,
        }
    }
}
```

### ä»»åŠ¡ç±»å‹å®šä¹‰

```rust
// src/node-core/src/task.rs

#[derive(Debug, Clone)]
pub enum Task {
    // L1 ä¸“å±ä»»åŠ¡
    Consensus(ConsensusTask),
    ZkProof(ZkProofTask),
    StateValidation(StateValidationTask),
    
    // L2 ä¸“å±ä»»åŠ¡
    TxExecution(TxExecutionTask),
    BlockBuilding(BlockBuildingTask),
    StateUpdate(StateUpdateTask),
    
    // L3 ä¸“å±ä»»åŠ¡
    Query(QueryTask),
    TxForwarding(TxForwardingTask),
    CacheUpdate(CacheUpdateTask),
    
    // L4 ä¸“å±ä»»åŠ¡
    LocalOp(LocalOpTask),
    TxSigning(TxSigningTask),
    
    // è·¨å±‚ä»»åŠ¡
    LargeComputation(LargeComputationTask),
    DataSync(DataSyncTask),
}

impl Task {
    /// ä»»åŠ¡çš„è®¡ç®—å¤æ‚åº¦ (0-100)
    pub fn complexity(&self) -> u8 {
        match self {
            Task::Consensus(_) => 90,
            Task::ZkProof(_) => 95,
            Task::TxExecution(_) => 60,
            Task::Query(_) => 20,
            Task::LocalOp(_) => 10,
            _ => 50,
        }
    }
    
    /// ä»»åŠ¡éœ€è¦çš„æœ€ä½èŠ‚ç‚¹ç±»å‹
    pub fn required_node_type(&self) -> NodeType {
        match self {
            Task::Consensus(_) | Task::ZkProof(_) => NodeType::L1Supernode,
            Task::TxExecution(_) | Task::BlockBuilding(_) => NodeType::L2Miner,
            Task::Query(_) | Task::TxForwarding(_) => NodeType::L3Edge,
            _ => NodeType::L4Mobile,
        }
    }
}
```

### è´Ÿè½½å‡è¡¡

```rust
// src/node-core/src/load_balancer.rs

pub struct LoadBalancer {
    nodes: DashMap<NodeId, NodeInfo>,
}

pub struct NodeInfo {
    pub node_type: NodeType,
    pub current_load: AtomicU8,  // 0-100
    pub queue_length: AtomicUsize,
    pub last_heartbeat: AtomicU64,
}

impl LoadBalancer {
    /// é€‰æ‹©æœ€ä½³èŠ‚ç‚¹æ‰§è¡Œä»»åŠ¡
    pub fn select_node(&self, task: &Task) -> Option<NodeId> {
        let required_type = task.required_node_type();
        
        // 1. è¿‡æ»¤ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹
        let candidates: Vec<_> = self.nodes
            .iter()
            .filter(|n| n.node_type >= required_type)
            .filter(|n| n.current_load.load(Ordering::Relaxed) < 80)
            .collect();
        
        if candidates.is_empty() {
            return None;
        }
        
        // 2. è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„å¾—åˆ†
        let mut best_node = None;
        let mut best_score = f64::NEG_INFINITY;
        
        for node in candidates {
            let score = self.calculate_score(node, task);
            if score > best_score {
                best_score = score;
                best_node = Some(*node.key());
            }
        }
        
        best_node
    }
    
    fn calculate_score(&self, node: &NodeInfo, task: &Task) -> f64 {
        let load = node.current_load.load(Ordering::Relaxed) as f64 / 100.0;
        let queue = node.queue_length.load(Ordering::Relaxed) as f64;
        
        // å¾—åˆ† = èƒ½åŠ› - è´Ÿè½½ - é˜Ÿåˆ—
        let capability = match node.node_type {
            NodeType::L1Supernode => 1.0,
            NodeType::L2Miner => 0.7,
            NodeType::L3Edge => 0.4,
            NodeType::L4Mobile => 0.1,
        };
        
        capability - (load * 0.5) - (queue * 0.01)
    }
}
```

---

## ğŸ’¾ å­˜å‚¨åˆ†å±‚ç®¡ç†

### å››å±‚å­˜å‚¨ç­–ç•¥

```
L1: å®Œæ•´çŠ¶æ€ (100%)
â”œâ”€â”€ RocksDB (10-100 TB)
â”œâ”€â”€ æ‰€æœ‰å†å²åŒºå—
â”œâ”€â”€ æ‰€æœ‰å†å²äº¤æ˜“
â””â”€â”€ æ‰€æœ‰çŠ¶æ€å˜æ›´

L2: éƒ¨åˆ†çŠ¶æ€ (æœ€è¿‘ N ä¸ªåŒºå—)
â”œâ”€â”€ RocksDB (500 GB - 2 TB)
â”œâ”€â”€ æœ€è¿‘ 10000 åŒºå—
â”œâ”€â”€ æ´»è·ƒè´¦æˆ·çŠ¶æ€
â””â”€â”€ å®šæœŸä» L1 è£å‰ª

L3: çƒ­ç‚¹æ•°æ® (é«˜é¢‘è®¿é—®)
â”œâ”€â”€ LRU Cache (100 GB - 1 TB)
â”œâ”€â”€ çƒ­é—¨è´¦æˆ·ä½™é¢
â”œâ”€â”€ NFT å…ƒæ•°æ®
â””â”€â”€ æ¸¸æˆå®æ—¶çŠ¶æ€

L4: æœ¬åœ°ç¼“å­˜ (ç”¨æˆ·ä¸“å±)
â”œâ”€â”€ SQLite (1-10 GB)
â”œâ”€â”€ ç”¨æˆ·è´¦æˆ·
â”œâ”€â”€ æœ€è¿‘äº¤æ˜“
â””â”€â”€ ç¦»çº¿é˜Ÿåˆ—
```

### çŠ¶æ€åŒæ­¥åè®®

```rust
// src/node-core/src/state_sync.rs

pub struct StateSyncProtocol {
    local_node_type: NodeType,
    peers: HashMap<NodeType, Vec<PeerConnection>>,
}

impl StateSyncProtocol {
    /// L4 â†’ L3 åŒæ­¥
    pub async fn sync_l4_to_l3(&self, user_data: UserData) -> Result<()> {
        let l3_peer = self.find_nearest_l3()?;
        
        // 1. æ‰¹é‡æäº¤äº¤æ˜“
        if user_data.pending_txs.len() > 0 {
            l3_peer.batch_submit(user_data.pending_txs).await?;
        }
        
        // 2. è·å–æœ€æ–°çŠ¶æ€
        let latest_state = l3_peer.query_user_state(user_data.address).await?;
        
        // 3. æ›´æ–°æœ¬åœ°ç¼“å­˜
        self.update_local_cache(latest_state)?;
        
        Ok(())
    }
    
    /// L3 â†’ L2 åŒæ­¥
    pub async fn sync_l3_to_l2(&self, cache_miss: Vec<Key>) -> Result<()> {
        let l2_peer = self.find_best_l2()?;
        
        // 1. æ‰¹é‡æŸ¥è¯¢ç¼ºå¤±æ•°æ®
        let data = l2_peer.batch_query(cache_miss).await?;
        
        // 2. æ›´æ–° L3 ç¼“å­˜
        self.update_cache(data)?;
        
        Ok(())
    }
    
    /// L2 â†’ L1 åŒæ­¥
    pub async fn sync_l2_to_l1(&self, block: Block) -> Result<()> {
        let l1_peer = self.find_l1_validator()?;
        
        // 1. æäº¤åŒºå—åˆ° L1 å…±è¯†
        l1_peer.submit_block(block).await?;
        
        // 2. ç­‰å¾…ç¡®è®¤
        let confirmed = l1_peer.wait_confirmation(block.hash()).await?;
        
        // 3. è£å‰ªæ—§æ•°æ® (å¦‚æœéœ€è¦)
        if self.should_prune() {
            self.prune_old_blocks().await?;
        }
        
        Ok(())
    }
}
```

### æ™ºèƒ½ç¼“å­˜ç­–ç•¥

```rust
// src/node-core/src/cache.rs

pub struct SmartCache {
    lru: LruCache<Key, Value>,
    access_freq: DashMap<Key, AtomicU64>,
    prefetch_enabled: bool,
}

impl SmartCache {
    /// é¢„å–çƒ­ç‚¹æ•°æ®
    pub async fn prefetch_hot_data(&self) -> Result<()> {
        if !self.prefetch_enabled {
            return Ok(());
        }
        
        // 1. åˆ†æè®¿é—®é¢‘ç‡
        let hot_keys: Vec<_> = self.access_freq
            .iter()
            .map(|entry| (entry.key().clone(), entry.value().load(Ordering::Relaxed)))
            .collect();
        
        // 2. æŒ‰é¢‘ç‡æ’åº
        let mut hot_keys = hot_keys;
        hot_keys.sort_by(|a, b| b.1.cmp(&a.1));
        
        // 3. é¢„å– Top 1000
        let top_keys: Vec<_> = hot_keys.iter().take(1000).map(|(k, _)| k.clone()).collect();
        let data = self.batch_fetch_from_upper_layer(top_keys).await?;
        
        // 4. æ›´æ–°ç¼“å­˜
        for (key, value) in data {
            self.lru.put(key, value);
        }
        
        Ok(())
    }
}
```

---

## âš¡ ç®—åŠ›è°ƒåº¦ç­–ç•¥

### å…¨ç½‘ç®—åŠ›æ± 

```rust
// src/node-core/src/compute_pool.rs

pub struct ComputePool {
    nodes: DashMap<NodeId, ComputeNode>,
    task_queue: Arc<Mutex<VecDeque<ComputeTask>>>,
}

pub struct ComputeNode {
    pub id: NodeId,
    pub node_type: NodeType,
    pub cpu_cores: usize,
    pub available_cores: AtomicUsize,
    pub gpu_available: bool,
    pub current_tasks: DashMap<TaskId, ComputeTask>,
}

impl ComputePool {
    /// æäº¤è®¡ç®—ä»»åŠ¡åˆ°å…¨ç½‘ç®—åŠ›æ± 
    pub async fn submit_task(&self, task: ComputeTask) -> Result<TaskId> {
        let task_id = TaskId::new();
        
        // 1. è¯„ä¼°ä»»åŠ¡éœ€æ±‚
        let requirement = task.compute_requirement();
        
        // 2. æŸ¥æ‰¾åˆé€‚çš„èŠ‚ç‚¹
        let suitable_nodes = self.find_suitable_nodes(&requirement)?;
        
        if suitable_nodes.is_empty() {
            // æ— å¯ç”¨èŠ‚ç‚¹,åŠ å…¥é˜Ÿåˆ—
            self.task_queue.lock().await.push_back(task);
            return Ok(task_id);
        }
        
        // 3. é€‰æ‹©æœ€ä½³èŠ‚ç‚¹ (è´Ÿè½½æœ€ä½)
        let best_node = self.select_best_node(&suitable_nodes);
        
        // 4. åˆ†é…ä»»åŠ¡
        self.assign_task(best_node, task_id, task).await?;
        
        Ok(task_id)
    }
    
    /// åˆ†å¸ƒå¼å¹¶è¡Œè®¡ç®— (MapReduce)
    pub async fn distributed_compute<T, R>(
        &self,
        data: Vec<T>,
        map_fn: fn(T) -> R,
        reduce_fn: fn(Vec<R>) -> R,
    ) -> Result<R> {
        // 1. å°†æ•°æ®åˆ†ç‰‡
        let chunk_size = (data.len() + self.nodes.len() - 1) / self.nodes.len();
        let chunks: Vec<_> = data.chunks(chunk_size).collect();
        
        // 2. åˆ†å‘åˆ°å„èŠ‚ç‚¹ (Map é˜¶æ®µ)
        let mut futures = Vec::new();
        for (i, chunk) in chunks.iter().enumerate() {
            let node = self.nodes.iter().nth(i % self.nodes.len()).unwrap();
            let future = node.execute_map(chunk, map_fn);
            futures.push(future);
        }
        
        // 3. ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹å®Œæˆ
        let results = futures::future::join_all(futures).await;
        
        // 4. Reduce é˜¶æ®µ
        let final_result = reduce_fn(results);
        
        Ok(final_result)
    }
}
```

### ZK è¯æ˜çš„ GPU åŠ é€Ÿè°ƒåº¦

```rust
// src/node-core/src/zk_scheduler.rs

pub struct ZkProofScheduler {
    gpu_nodes: Vec<NodeId>,  // æœ‰ GPU çš„ L1 èŠ‚ç‚¹
    cpu_fallback: Vec<NodeId>,  // CPU fallback
}

impl ZkProofScheduler {
    /// è°ƒåº¦ ZK è¯æ˜ä»»åŠ¡
    pub async fn schedule_proof(&self, proof_task: ZkProofTask) -> Result<Proof> {
        // 1. ä¼˜å…ˆå°è¯• GPU èŠ‚ç‚¹
        if let Some(gpu_node) = self.find_available_gpu_node() {
            match self.submit_to_gpu(gpu_node, proof_task.clone()).await {
                Ok(proof) => return Ok(proof),
                Err(e) => {
                    warn!("GPU proof failed: {}, fallback to CPU", e);
                }
            }
        }
        
        // 2. GPU ä¸å¯ç”¨æˆ–å¤±è´¥,fallback åˆ° CPU
        let cpu_node = self.find_available_cpu_node()?;
        let proof = self.submit_to_cpu(cpu_node, proof_task).await?;
        
        Ok(proof)
    }
    
    /// æ‰¹é‡ ZK è¯æ˜ (å……åˆ†åˆ©ç”¨ GPU)
    pub async fn batch_prove(&self, tasks: Vec<ZkProofTask>) -> Result<Vec<Proof>> {
        // 1. æ”¶é›†æ‰€æœ‰ GPU èŠ‚ç‚¹
        let gpu_nodes: Vec<_> = self.gpu_nodes
            .iter()
            .filter(|id| self.is_node_available(id))
            .collect();
        
        if gpu_nodes.is_empty() {
            // æ—  GPU,å…¨éƒ¨ç”¨ CPU
            return self.cpu_batch_prove(tasks).await;
        }
        
        // 2. ä»»åŠ¡åˆ†ç‰‡ (æ¯ä¸ª GPU èŠ‚ç‚¹å¤„ç†ä¸€éƒ¨åˆ†)
        let chunk_size = (tasks.len() + gpu_nodes.len() - 1) / gpu_nodes.len();
        
        // 3. å¹¶è¡Œæäº¤
        let mut futures = Vec::new();
        for (i, chunk) in tasks.chunks(chunk_size).enumerate() {
            let node = gpu_nodes[i % gpu_nodes.len()];
            let future = self.submit_batch_to_gpu(*node, chunk.to_vec());
            futures.push(future);
        }
        
        // 4. æ±‡æ€»ç»“æœ
        let results = futures::future::try_join_all(futures).await?;
        let proofs = results.into_iter().flatten().collect();
        
        Ok(proofs)
    }
}
```

### åŠ¨æ€è´Ÿè½½è°ƒæ•´

```rust
// src/node-core/src/load_adjuster.rs

pub struct LoadAdjuster {
    metrics: Arc<Mutex<NodeMetrics>>,
}

pub struct NodeMetrics {
    pub cpu_usage: f64,
    pub memory_usage: f64,
    pub disk_io: f64,
    pub network_io: f64,
    pub task_queue_length: usize,
}

impl LoadAdjuster {
    /// æ ¹æ®è´Ÿè½½åŠ¨æ€è°ƒæ•´èŠ‚ç‚¹è¡Œä¸º
    pub async fn adjust(&self) -> Result<()> {
        let metrics = self.metrics.lock().await;
        
        // 1. CPU è¿‡è½½ â†’ é™ä½å¹¶è¡Œåº¦
        if metrics.cpu_usage > 0.9 {
            self.reduce_parallelism().await?;
            self.reject_new_tasks().await?;
        }
        
        // 2. å†…å­˜ä¸è¶³ â†’ æ¸…ç†ç¼“å­˜
        if metrics.memory_usage > 0.85 {
            self.clear_cache().await?;
            self.trigger_gc().await?;
        }
        
        // 3. ç£ç›˜ I/O é«˜ â†’ é™æµ
        if metrics.disk_io > 0.8 {
            self.throttle_disk_ops().await?;
        }
        
        // 4. ç½‘ç»œæ‹¥å µ â†’ æ‰¹é‡ä¼ è¾“
        if metrics.network_io > 0.8 {
            self.enable_batch_mode().await?;
        }
        
        // 5. ä»»åŠ¡é˜Ÿåˆ—ç§¯å‹ â†’ è¯·æ±‚æ”¯æ´
        if metrics.task_queue_length > 1000 {
            self.request_help_from_peers().await?;
        }
        
        Ok(())
    }
}
```

---

## ğŸŒ ç¥ç»ç½‘ç»œè·¯ç”±å¯»å€ç³»ç»Ÿ

### æ ¸å¿ƒé—®é¢˜

ä¼ ç»Ÿ P2P ç½‘ç»œçš„ç—›ç‚¹:
```
âŒ èŠ‚ç‚¹å‘ç°æ…¢ (DHT æŸ¥è¯¢éœ€è¦å¤šè·³,å»¶è¿Ÿé«˜)
âŒ NAT ç©¿é€æˆåŠŸç‡ä½ (STUN/TURN æˆåŠŸç‡ 60-70%)
âŒ è¿æ¥å»ºç«‹æ…¢ (éœ€è¦å¤šæ¬¡æ¡æ‰‹å°è¯•)
âŒ æ— æ³•æ„ŸçŸ¥èŠ‚ç‚¹èƒ½åŠ› (ä¸çŸ¥é“å¯¹æ–¹æ˜¯ L1/L2/L3/L4)
âŒ æ— æ³•æ™ºèƒ½è·¯ç”± (æ— æ³•æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æœ€ä½³èŠ‚ç‚¹)
```

**SuperVM è§£å†³æ–¹æ¡ˆ**: ç±»ä¼¼ DNS çš„åˆ†å±‚å¯»å€æœåŠ¡ + æ™ºèƒ½è·¯ç”±

### è®¾è®¡ç†å¿µ

```
ä¼ ç»Ÿ DNS:
ç”¨æˆ· â†’ æœ¬åœ° DNS â†’ æ ¹ DNS â†’ TLD DNS â†’ æƒå¨ DNS â†’ IPåœ°å€

SuperVM ç¥ç»ç½‘ç»œå¯»å€:
L4 å®¢æˆ·ç«¯ â†’ L3 è¾¹ç¼˜èŠ‚ç‚¹ (åŒºåŸŸè·¯ç”±è¡¨) â†’ L2 çŸ¿æœº (å…¨å±€è·¯ç”±è¡¨) â†’ L1 è¶…ç®— (æ ¹è·¯ç”±è¡¨) â†’ ç›®æ ‡èŠ‚ç‚¹

ç‰¹ç‚¹:
âœ… åˆ†å±‚ç¼“å­˜ (L3 ç¼“å­˜çƒ­é—¨èŠ‚ç‚¹,L2 ç¼“å­˜å…¨å±€è·¯ç”±,L1 æ˜¯æƒå¨æº)
âœ… å°±è¿‘æœåŠ¡ (L4 ä¼˜å…ˆæŸ¥è¯¢æœ€è¿‘çš„ L3)
âœ… èƒ½åŠ›æ„ŸçŸ¥ (æ¯ä¸ªèŠ‚ç‚¹è®°å½•è‡ªå·±çš„ç¡¬ä»¶èƒ½åŠ›å’Œä»»åŠ¡ç±»å‹)
âœ… æ™ºèƒ½è·¯ç”± (æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä½³èŠ‚ç‚¹)
âœ… å¿«é€Ÿç©¿é€ (L3 èŠ‚ç‚¹å……å½“ relay,æˆåŠŸç‡ 95%+)
```

### æ¶æ„è®¾è®¡

#### 1. èŠ‚ç‚¹ ID ä¸åœ°å€ç³»ç»Ÿ

```rust
// src/node-core/src/addressing.rs

use libp2p::PeerId;
use std::net::IpAddr;

/// èŠ‚ç‚¹å…¨å±€å”¯ä¸€æ ‡è¯†ç¬¦
#[derive(Debug, Clone, Hash, Eq, PartialEq)]
pub struct NodeAddress {
    /// libp2p PeerId (åŸºäºå…¬é’¥ç”Ÿæˆ,å…¨å±€å”¯ä¸€)
    pub peer_id: PeerId,
    
    /// èŠ‚ç‚¹ç±»å‹ (L1/L2/L3/L4)
    pub node_type: NodeType,
    
    /// åœ°ç†ä½ç½® (åŒºåŸŸä»£ç )
    pub region: Region,
    
    /// å…¬ç½‘åœ°å€ (å¦‚æœæœ‰)
    pub public_addrs: Vec<Multiaddr>,
    
    /// å†…ç½‘åœ°å€
    pub private_addrs: Vec<Multiaddr>,
    
    /// NAT ç±»å‹
    pub nat_type: NatType,
    
    /// ç¡¬ä»¶èƒ½åŠ›
    pub capability: HardwareCapability,
    
    /// å½“å‰è´Ÿè½½ (0-100)
    pub load: u8,
    
    /// æœ€åå¿ƒè·³æ—¶é—´
    pub last_seen: u64,
}

/// NAT ç±»å‹
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum NatType {
    Public,              // å…¬ç½‘ IP
    FullCone,            // å®Œå…¨é”¥å½¢ NAT (æ˜“ç©¿é€)
    RestrictedCone,      // å—é™é”¥å½¢ NAT
    PortRestricted,      // ç«¯å£å—é™é”¥å½¢ NAT
    Symmetric,           // å¯¹ç§°å‹ NAT (éš¾ç©¿é€)
    Unknown,
}

/// åœ°ç†åŒºåŸŸ
#[derive(Debug, Clone, Copy, Hash, Eq, PartialEq)]
pub enum Region {
    // äºšæ´²
    AsiaCN,        // ä¸­å›½
    AsiaJP,        // æ—¥æœ¬
    AsiaSG,        // æ–°åŠ å¡
    AsiaKR,        // éŸ©å›½
    
    // åŒ—ç¾
    NAWest,        // åŒ—ç¾è¥¿éƒ¨
    NAEast,        // åŒ—ç¾ä¸œéƒ¨
    
    // æ¬§æ´²
    EUWest,        // è¥¿æ¬§
    EUEast,        // ä¸œæ¬§
    
    // å…¶ä»–
    Other,
}

impl Region {
    /// è®¡ç®—ä¸¤ä¸ªåŒºåŸŸä¹‹é—´çš„å»¶è¿Ÿä¼°è®¡ (ms)
    pub fn latency_to(&self, other: &Region) -> u64 {
        match (self, other) {
            (a, b) if a == b => 5,              // åŒåŒºåŸŸ 5ms
            (Region::AsiaCN, Region::AsiaJP) => 30,
            (Region::AsiaCN, Region::AsiaSG) => 50,
            (Region::AsiaCN, Region::NAWest) => 150,
            (Region::AsiaCN, Region::EUWest) => 200,
            _ => 100,  // é»˜è®¤è·¨åŒºåŸŸ 100ms
        }
    }
}
```

#### 2. å››å±‚è·¯ç”±è¡¨

```rust
// src/node-core/src/routing_table.rs

use dashmap::DashMap;
use lru::LruCache;

/// è·¯ç”±è¡¨æ¥å£
pub trait RoutingTable: Send + Sync {
    /// æ³¨å†ŒèŠ‚ç‚¹
    async fn register(&self, node: NodeAddress) -> Result<()>;
    
    /// æŸ¥è¯¢èŠ‚ç‚¹
    async fn lookup(&self, peer_id: &PeerId) -> Option<NodeAddress>;
    
    /// æ ¹æ®æ¡ä»¶æŸ¥è¯¢èŠ‚ç‚¹
    async fn find_nodes(&self, filter: NodeFilter) -> Vec<NodeAddress>;
    
    /// å¿ƒè·³æ›´æ–°
    async fn heartbeat(&self, peer_id: &PeerId, load: u8) -> Result<()>;
    
    /// åˆ é™¤ä¸‹çº¿èŠ‚ç‚¹
    async fn remove(&self, peer_id: &PeerId) -> Result<()>;
}

/// L1 æ ¹è·¯ç”±è¡¨ (æƒå¨è·¯ç”±è¡¨)
pub struct L1RootRoutingTable {
    /// æ‰€æœ‰èŠ‚ç‚¹çš„å®Œæ•´ä¿¡æ¯ (æŒä¹…åŒ–åˆ° RocksDB)
    nodes: Arc<RocksDB>,
    
    /// å†…å­˜ç´¢å¼• (PeerId â†’ NodeAddress)
    index: DashMap<PeerId, NodeAddress>,
    
    /// æŒ‰åŒºåŸŸç´¢å¼•
    region_index: DashMap<Region, Vec<PeerId>>,
    
    /// æŒ‰èŠ‚ç‚¹ç±»å‹ç´¢å¼•
    type_index: DashMap<NodeType, Vec<PeerId>>,
}

impl L1RootRoutingTable {
    /// åˆ›å»ºæ ¹è·¯ç”±è¡¨
    pub fn new(db: Arc<RocksDB>) -> Self {
        Self {
            nodes: db,
            index: DashMap::new(),
            region_index: DashMap::new(),
            type_index: DashMap::new(),
        }
    }
    
    /// ä» RocksDB åŠ è½½å…¨éƒ¨èŠ‚ç‚¹
    pub async fn load_from_db(&self) -> Result<()> {
        let mut iter = self.nodes.iterator(IteratorMode::Start);
        while let Some((key, value)) = iter.next() {
            let peer_id = PeerId::from_bytes(&key)?;
            let node: NodeAddress = bincode::deserialize(&value)?;
            
            self.index.insert(peer_id, node.clone());
            
            // æ›´æ–°ç´¢å¼•
            self.region_index
                .entry(node.region)
                .or_insert(Vec::new())
                .push(peer_id);
            
            self.type_index
                .entry(node.node_type)
                .or_insert(Vec::new())
                .push(peer_id);
        }
        
        Ok(())
    }
    
    /// æŸ¥è¯¢æœ€ä½³èŠ‚ç‚¹ (æ ¹æ®ä»»åŠ¡å’ŒåŒºåŸŸ)
    pub async fn find_best_node(
        &self,
        task_type: TaskType,
        requester_region: Region,
    ) -> Option<NodeAddress> {
        let required_type = task_type.required_node_type();
        
        // 1. è·å–ç¬¦åˆç±»å‹çš„èŠ‚ç‚¹
        let candidates = self.type_index
            .get(&required_type)?
            .value()
            .clone();
        
        // 2. æŒ‰è·ç¦»å’Œè´Ÿè½½æ’åº
        let mut scored: Vec<_> = candidates
            .iter()
            .filter_map(|peer_id| self.index.get(peer_id))
            .map(|node| {
                let latency = requester_region.latency_to(&node.region);
                let load = node.load as u64;
                let score = 1000 - latency - load * 5;
                (score, node.clone())
            })
            .collect();
        
        scored.sort_by_key(|(score, _)| std::cmp::Reverse(*score));
        
        scored.first().map(|(_, node)| node.clone())
    }
}

/// L2 å…¨å±€è·¯ç”±è¡¨ (ç¼“å­˜æœ€è¿‘ 10 ä¸‡ä¸ªèŠ‚ç‚¹)
pub struct L2GlobalRoutingTable {
    /// LRU ç¼“å­˜ (æœ€è¿‘è®¿é—®çš„èŠ‚ç‚¹)
    cache: Arc<Mutex<LruCache<PeerId, NodeAddress>>>,
    
    /// åŒºåŸŸç´¢å¼• (å¿«é€ŸæŸ¥è¯¢åŒåŒºåŸŸèŠ‚ç‚¹)
    region_cache: DashMap<Region, Vec<PeerId>>,
    
    /// ä¸Šæ¸¸ L1 èŠ‚ç‚¹
    l1_nodes: Vec<PeerId>,
}

impl L2GlobalRoutingTable {
    pub fn new(capacity: usize, l1_nodes: Vec<PeerId>) -> Self {
        Self {
            cache: Arc::new(Mutex::new(LruCache::new(capacity))),
            region_cache: DashMap::new(),
            l1_nodes,
        }
    }
    
    /// æŸ¥è¯¢èŠ‚ç‚¹ (ç¼“å­˜æœªå‘½ä¸­åˆ™æŸ¥è¯¢ L1)
    pub async fn lookup(&self, peer_id: &PeerId) -> Option<NodeAddress> {
        // 1. æŸ¥ç¼“å­˜
        if let Some(node) = self.cache.lock().await.get(peer_id) {
            return Some(node.clone());
        }
        
        // 2. ç¼“å­˜æœªå‘½ä¸­,æŸ¥è¯¢ L1
        let node = self.query_l1(peer_id).await?;
        
        // 3. æ›´æ–°ç¼“å­˜
        self.cache.lock().await.put(*peer_id, node.clone());
        
        Some(node)
    }
    
    async fn query_l1(&self, peer_id: &PeerId) -> Option<NodeAddress> {
        // éšæœºé€‰æ‹©ä¸€ä¸ª L1 èŠ‚ç‚¹æŸ¥è¯¢
        let l1 = self.l1_nodes.choose(&mut rand::thread_rng())?;
        
        // RPC æŸ¥è¯¢
        let response = self.rpc_call(l1, "routing.lookup", peer_id).await.ok()?;
        
        Some(response)
    }
}

/// L3 åŒºåŸŸè·¯ç”±è¡¨ (ç¼“å­˜åŒåŒºåŸŸèŠ‚ç‚¹)
pub struct L3RegionalRoutingTable {
    /// æœ¬åŒºåŸŸ
    local_region: Region,
    
    /// LRU ç¼“å­˜ (æœ€è¿‘è®¿é—®çš„ 1 ä¸‡ä¸ªèŠ‚ç‚¹)
    cache: Arc<Mutex<LruCache<PeerId, NodeAddress>>>,
    
    /// åŒåŒºåŸŸèŠ‚ç‚¹åˆ—è¡¨
    regional_nodes: DashMap<PeerId, NodeAddress>,
    
    /// ä¸Šæ¸¸ L2 èŠ‚ç‚¹
    l2_nodes: Vec<PeerId>,
}

impl L3RegionalRoutingTable {
    /// æŸ¥è¯¢èŠ‚ç‚¹ (ä¼˜å…ˆåŒåŒºåŸŸ)
    pub async fn lookup(&self, peer_id: &PeerId) -> Option<NodeAddress> {
        // 1. æŸ¥åŒåŒºåŸŸèŠ‚ç‚¹
        if let Some(node) = self.regional_nodes.get(peer_id) {
            return Some(node.clone());
        }
        
        // 2. æŸ¥ç¼“å­˜
        if let Some(node) = self.cache.lock().await.get(peer_id) {
            return Some(node.clone());
        }
        
        // 3. æŸ¥è¯¢ L2
        let node = self.query_l2(peer_id).await?;
        
        // 4. æ›´æ–°ç¼“å­˜
        self.cache.lock().await.put(*peer_id, node.clone());
        
        Some(node)
    }
    
    /// å¹¿æ’­æœ¬åœ°èŠ‚ç‚¹åˆ°åŒºåŸŸ
    pub async fn broadcast_local_node(&self, node: NodeAddress) -> Result<()> {
        if node.region == self.local_region {
            self.regional_nodes.insert(node.peer_id, node.clone());
        }
        
        Ok(())
    }
}

/// L4 æœ¬åœ°è·¯ç”±è¡¨ (è½»é‡çº§å‚ä¸è·¯ç”±)
/// 
/// **è®¾è®¡ç†å¿µ**: L4 ç§»åŠ¨èŠ‚ç‚¹è™½ç„¶èµ„æºæœ‰é™,ä½†ä¹Ÿå¯ä»¥å‚ä¸ç½‘ç»œè·¯ç”±:
/// 1. **ä¸´æ—¶ç¼“å­˜**: ç¼“å­˜æœ€è¿‘è¿æ¥çš„ 100-500 ä¸ªèŠ‚ç‚¹ (æ ¹æ®å†…å­˜åŠ¨æ€è°ƒæ•´)
/// 2. **è·¯ç”±ä¸­ç»§**: å¯ä»¥ä¸ºå…¶ä»– L4 èŠ‚ç‚¹æä¾›è·¯ç”±æŸ¥è¯¢æœåŠ¡ (å‡è½» L3 è´Ÿè½½)
/// 3. **ç©¿é€ååŠ©**: å¯ä»¥å……å½“ NAT æ‰“æ´çš„åè°ƒè€… (å¸®åŠ©å…¶ä»– L4 èŠ‚ç‚¹ç©¿é€)
/// 4. **P2P å‘ç°**: å¯ä»¥é€šè¿‡è“ç‰™/WiFi Direct åœ¨æœ¬åœ°ç½‘ç»œå‘ç°å…¶ä»– L4 èŠ‚ç‚¹
pub struct L4LocalRoutingTable {
    /// å°å‹ LRU ç¼“å­˜ (åŠ¨æ€å¤§å°: 100-500 èŠ‚ç‚¹)
    cache: Arc<Mutex<LruCache<PeerId, NodeAddress>>>,
    
    /// æœ€è¿‘è¿æ¥çš„ L3 èŠ‚ç‚¹ (ä½œä¸ºä¸Šæ¸¸è·¯ç”±)
    l3_nodes: Vec<PeerId>,
    
    /// åŒå±€åŸŸç½‘çš„ L4 èŠ‚ç‚¹ (é€šè¿‡ mDNS/è“ç‰™å‘ç°)
    local_l4_peers: DashMap<PeerId, NodeAddress>,
    
    /// æ˜¯å¦å¯ç”¨è·¯ç”±ä¸­ç»§åŠŸèƒ½ (é»˜è®¤å…³é—­,èŠ‚çœèµ„æº)
    enable_relay: AtomicBool,
    
    /// æ˜¯å¦å¯ç”¨ NAT ååŠ©åŠŸèƒ½
    enable_nat_assist: AtomicBool,
    
    /// è·¯ç”±æŸ¥è¯¢ç»Ÿè®¡ (ç”¨äºåˆ¤æ–­æ˜¯å¦å‡çº§ä¸ºä¸­ç»§èŠ‚ç‚¹)
    query_stats: Arc<Mutex<QueryStats>>,
}

#[derive(Default)]
pub struct QueryStats {
    /// è¢«è¯·æ±‚æ¬¡æ•°
    request_count: u64,
    /// ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    cache_hit_count: u64,
    /// ä¸Šæ¬¡ç»Ÿè®¡é‡ç½®æ—¶é—´
    last_reset: u64,
}

impl L4LocalRoutingTable {
    pub fn new(cache_capacity: usize) -> Self {
        Self {
            cache: Arc::new(Mutex::new(LruCache::new(cache_capacity))),
            l3_nodes: Vec::new(),
            local_l4_peers: DashMap::new(),
            enable_relay: AtomicBool::new(false),
            enable_nat_assist: AtomicBool::new(false),
            query_stats: Arc::new(Mutex::new(QueryStats::default())),
        }
    }
    
    /// æ ¹æ®è®¾å¤‡å†…å­˜è‡ªåŠ¨è°ƒæ•´ç¼“å­˜å¤§å°
    pub fn auto_adjust_cache_size(available_memory_mb: usize) -> usize {
        match available_memory_mb {
            0..=512 => 50,        // ä½å†…å­˜è®¾å¤‡: 50 èŠ‚ç‚¹
            513..=1024 => 100,    // ä¸­ç­‰è®¾å¤‡: 100 èŠ‚ç‚¹
            1025..=2048 => 200,   // è¾ƒå¥½è®¾å¤‡: 200 èŠ‚ç‚¹
            2049..=4096 => 300,   // é«˜ç«¯è®¾å¤‡: 300 èŠ‚ç‚¹
            _ => 500,             // æ——èˆ°è®¾å¤‡: 500 èŠ‚ç‚¹
        }
    }
    
    /// æŸ¥è¯¢èŠ‚ç‚¹ (å¤šçº§æŸ¥æ‰¾)
    pub async fn lookup(&self, peer_id: &PeerId) -> Option<NodeAddress> {
        // æ›´æ–°ç»Ÿè®¡
        self.query_stats.lock().await.request_count += 1;
        
        // 1. æŸ¥æœ¬åœ°ç¼“å­˜
        if let Some(node) = self.cache.lock().await.get(peer_id) {
            self.query_stats.lock().await.cache_hit_count += 1;
            return Some(node.clone());
        }
        
        // 2. æŸ¥åŒå±€åŸŸç½‘çš„ L4 èŠ‚ç‚¹
        if let Some(node) = self.local_l4_peers.get(peer_id) {
            let result = node.clone();
            self.cache.lock().await.put(*peer_id, result.clone());
            return Some(result);
        }
        
        // 3. è¯¢é—®å…¶ä»– L4 èŠ‚ç‚¹ (å¦‚æœä»–ä»¬å¯ç”¨äº†ä¸­ç»§)
        if let Some(node) = self.query_peer_l4(peer_id).await {
            self.cache.lock().await.put(*peer_id, node.clone());
            return Some(node);
        }
        
        // 4. æŸ¥è¯¢ä¸Šæ¸¸ L3 èŠ‚ç‚¹
        let l3 = self.l3_nodes.first()?;
        let node = self.query_l3(l3, peer_id).await?;
        
        // 5. æ›´æ–°ç¼“å­˜
        self.cache.lock().await.put(*peer_id, node.clone());
        
        Some(node)
    }
    
    /// å‘å…¶ä»– L4 èŠ‚ç‚¹æŸ¥è¯¢ (P2P ååŠ©)
    async fn query_peer_l4(&self, peer_id: &PeerId) -> Option<NodeAddress> {
        // éå†åŒå±€åŸŸç½‘çš„ L4 èŠ‚ç‚¹
        for entry in self.local_l4_peers.iter() {
            let peer = entry.value();
            
            // åªæŸ¥è¯¢å¯ç”¨äº†ä¸­ç»§åŠŸèƒ½çš„èŠ‚ç‚¹
            if !peer.capability.enable_relay {
                continue;
            }
            
            // RPC æŸ¥è¯¢: "routing.lookup"
            if let Ok(node) = self.rpc_call(&peer.peer_id, "routing.lookup", peer_id).await {
                return Some(node);
            }
        }
        
        None
    }
    
    /// ä¸ºå…¶ä»–èŠ‚ç‚¹æä¾›è·¯ç”±æŸ¥è¯¢æœåŠ¡ (ä¸­ç»§åŠŸèƒ½)
    pub async fn handle_relay_query(&self, peer_id: &PeerId) -> Option<NodeAddress> {
        // åªæœ‰å¯ç”¨ä¸­ç»§æ—¶æ‰å“åº”
        if !self.enable_relay.load(Ordering::Relaxed) {
            return None;
        }
        
        // æŸ¥è¯¢æœ¬åœ°ç¼“å­˜
        self.cache.lock().await.get(peer_id).cloned()
    }
    
    /// æ³¨å†Œæœ¬åœ°å‘ç°çš„ L4 èŠ‚ç‚¹
    pub async fn register_local_peer(&self, node: NodeAddress) -> Result<()> {
        self.local_l4_peers.insert(node.peer_id, node.clone());
        
        // åŒæ—¶åŠ å…¥ç¼“å­˜
        self.cache.lock().await.put(node.peer_id, node);
        
        Ok(())
    }
    
    /// è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦åº”è¯¥å¯ç”¨ä¸­ç»§åŠŸèƒ½
    pub async fn auto_enable_relay(&self) -> Result<()> {
        let stats = self.query_stats.lock().await;
        
        // ç­–ç•¥: å¦‚æœè¢«è¯·æ±‚æ¬¡æ•° > 100 ä¸”ç¼“å­˜å‘½ä¸­ç‡ > 50%, å¯ç”¨ä¸­ç»§
        if stats.request_count > 100 {
            let hit_rate = stats.cache_hit_count as f64 / stats.request_count as f64;
            if hit_rate > 0.5 {
                self.enable_relay.store(true, Ordering::Relaxed);
                info!("L4 èŠ‚ç‚¹ç¼“å­˜å‘½ä¸­ç‡é«˜ ({:.2}%), è‡ªåŠ¨å¯ç”¨è·¯ç”±ä¸­ç»§åŠŸèƒ½", hit_rate * 100.0);
            }
        }
        
        Ok(())
    }
    
    /// NAT æ‰“æ´ååŠ© (ä¸ºå…¶ä»– L4 èŠ‚ç‚¹æä¾› STUN æœåŠ¡)
    pub async fn assist_nat_traversal(
        &self,
        requester: &PeerId,
        target: &PeerId,
    ) -> Result<NatAssistResult> {
        if !self.enable_nat_assist.load(Ordering::Relaxed) {
            return Err(anyhow!("NAT assist disabled"));
        }
        
        // 1. æ£€æŸ¥æ˜¯å¦çŸ¥é“ç›®æ ‡èŠ‚ç‚¹
        let target_node = self.cache.lock().await.get(target).cloned()
            .ok_or_else(|| anyhow!("Target not in cache"))?;
        
        // 2. å……å½“ STUN æœåŠ¡å™¨,å‘Šè¯‰è¯·æ±‚è€…ç›®æ ‡çš„å…¬ç½‘åœ°å€
        let stun_info = StunInfo {
            target_public_addr: target_node.public_addrs.first().cloned(),
            target_nat_type: target_node.nat_type,
            suggested_strategy: self.suggest_connection_strategy(
                &requester, 
                &target_node
            ),
        };
        
        Ok(NatAssistResult::Success(stun_info))
    }
    
    fn suggest_connection_strategy(
        &self,
        requester: &PeerId,
        target: &NodeAddress,
    ) -> ConnectionStrategy {
        match target.nat_type {
            NatType::Public => ConnectionStrategy::Direct,
            NatType::FullCone | NatType::RestrictedCone => ConnectionStrategy::HolePunch,
            NatType::Symmetric => ConnectionStrategy::NeedRelay,
            NatType::Unknown => ConnectionStrategy::TryAll,
        }
    }
    
    /// è“ç‰™/WiFi Direct æœ¬åœ°å‘ç°
    pub async fn discover_local_peers(&self) -> Result<Vec<NodeAddress>> {
        let mut discovered = Vec::new();
        
        // 1. mDNS å‘ç° (WiFi)
        #[cfg(feature = "mdns")]
        {
            let mdns_peers = self.mdns_discover().await?;
            discovered.extend(mdns_peers);
        }
        
        // 2. è“ç‰™å‘ç° (ç§»åŠ¨è®¾å¤‡)
        #[cfg(feature = "bluetooth")]
        {
            let bt_peers = self.bluetooth_discover().await?;
            discovered.extend(bt_peers);
        }
        
        // 3. æ³¨å†Œåˆ°æœ¬åœ°è·¯ç”±è¡¨
        for peer in &discovered {
            self.register_local_peer(peer.clone()).await?;
        }
        
        Ok(discovered)
    }
}

#[derive(Debug, Clone)]
pub struct StunInfo {
    pub target_public_addr: Option<Multiaddr>,
    pub target_nat_type: NatType,
    pub suggested_strategy: ConnectionStrategy,
}

#[derive(Debug, Clone)]
pub enum ConnectionStrategy {
    Direct,       // ç›´æ¥è¿æ¥
    HolePunch,    // NAT æ‰“æ´
    NeedRelay,    // éœ€è¦ä¸­ç»§
    TryAll,       // å°è¯•æ‰€æœ‰æ–¹æ³•
}

pub enum NatAssistResult {
    Success(StunInfo),
    TargetNotFound,
    NotSupported,
}
```

#### 3. æ™ºèƒ½å¯»å€åè®®

```rust
// src/node-core/src/addressing_protocol.rs

/// å¯»å€è¯·æ±‚
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AddressQuery {
    /// ç›®æ ‡èŠ‚ç‚¹ ID (å¯é€‰,å¦‚æœä¸ºç©ºåˆ™æ ¹æ®è¿‡æ»¤æ¡ä»¶æŸ¥è¯¢)
    pub target: Option<PeerId>,
    
    /// è¿‡æ»¤æ¡ä»¶
    pub filter: Option<NodeFilter>,
    
    /// è¯·æ±‚è€…ä¿¡æ¯
    pub requester: NodeAddress,
    
    /// ä»»åŠ¡ç±»å‹ (ç”¨äºæ™ºèƒ½è·¯ç”±)
    pub task_type: Option<TaskType>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeFilter {
    /// èŠ‚ç‚¹ç±»å‹
    pub node_type: Option<NodeType>,
    
    /// åŒºåŸŸ
    pub region: Option<Region>,
    
    /// æœ€å¤§å»¶è¿Ÿ (ms)
    pub max_latency: Option<u64>,
    
    /// æœ€å¤§è´Ÿè½½
    pub max_load: Option<u8>,
    
    /// ç¡¬ä»¶è¦æ±‚
    pub min_capability: Option<HardwareCapability>,
}

/// å¯»å€å“åº”
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AddressResponse {
    /// æ‰¾åˆ°çš„èŠ‚ç‚¹
    pub nodes: Vec<NodeAddress>,
    
    /// å»ºè®®çš„è¿æ¥æ–¹å¼
    pub connection_hints: Vec<ConnectionHint>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ConnectionHint {
    /// ç›´è¿ (å…¬ç½‘ IP)
    Direct { addr: Multiaddr },
    
    /// NAT ç©¿é€
    HolePunching { 
        public_addr: Multiaddr,
        private_addr: Multiaddr,
        nat_type: NatType,
    },
    
    /// ä¸­ç»§ (é€šè¿‡ L3 èŠ‚ç‚¹)
    Relay { 
        relay_node: PeerId,
        relay_addr: Multiaddr,
    },
}

/// å¯»å€æœåŠ¡
pub struct AddressingService {
    local_address: NodeAddress,
    routing_table: Arc<dyn RoutingTable>,
}

impl AddressingService {
    /// å¤„ç†å¯»å€æŸ¥è¯¢
    pub async fn handle_query(&self, query: AddressQuery) -> Result<AddressResponse> {
        // 1. å¦‚æœæœ‰æ˜ç¡®ç›®æ ‡,ç›´æ¥æŸ¥è¯¢
        if let Some(target) = query.target {
            if let Some(node) = self.routing_table.lookup(&target).await {
                let hints = self.generate_connection_hints(&node, &query.requester).await;
                return Ok(AddressResponse {
                    nodes: vec![node],
                    connection_hints: hints,
                });
            }
        }
        
        // 2. å¦‚æœæœ‰è¿‡æ»¤æ¡ä»¶,æŸ¥è¯¢ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹
        if let Some(filter) = query.filter {
            let nodes = self.routing_table.find_nodes(filter).await;
            
            // 3. æ™ºèƒ½æ’åº (å»¶è¿Ÿ + è´Ÿè½½ + èƒ½åŠ›)
            let mut scored: Vec<_> = nodes.into_iter()
                .map(|node| {
                    let score = self.calculate_score(&node, &query);
                    (score, node)
                })
                .collect();
            
            scored.sort_by_key(|(score, _)| std::cmp::Reverse(*score));
            
            // 4. è¿”å› Top 10
            let top_nodes: Vec<_> = scored.into_iter()
                .take(10)
                .map(|(_, node)| node)
                .collect();
            
            let hints = self.generate_connection_hints_batch(&top_nodes, &query.requester).await;
            
            return Ok(AddressResponse {
                nodes: top_nodes,
                connection_hints: hints,
            });
        }
        
        Err(anyhow!("No target or filter specified"))
    }
    
    fn calculate_score(&self, node: &NodeAddress, query: &AddressQuery) -> u64 {
        let mut score = 1000u64;
        
        // 1. å»¶è¿Ÿæƒ©ç½š
        let latency = query.requester.region.latency_to(&node.region);
        score = score.saturating_sub(latency);
        
        // 2. è´Ÿè½½æƒ©ç½š
        score = score.saturating_sub(node.load as u64 * 5);
        
        // 3. èƒ½åŠ›åŠ åˆ†
        if node.capability.cpu_cores >= 64 {
            score += 50;
        }
        if node.capability.has_gpu {
            score += 100;
        }
        
        // 4. NAT ç±»å‹åŠ åˆ† (æ˜“ç©¿é€çš„ä¼˜å…ˆ)
        match node.nat_type {
            NatType::Public => score += 100,
            NatType::FullCone => score += 80,
            NatType::RestrictedCone => score += 60,
            NatType::PortRestricted => score += 40,
            NatType::Symmetric => score += 20,
            NatType::Unknown => {},
        }
        
        score
    }
    
    async fn generate_connection_hints(
        &self,
        target: &NodeAddress,
        requester: &NodeAddress,
    ) -> Vec<ConnectionHint> {
        let mut hints = Vec::new();
        
        // 1. å¦‚æœç›®æ ‡æœ‰å…¬ç½‘ IP,ç›´è¿
        if target.nat_type == NatType::Public {
            for addr in &target.public_addrs {
                hints.push(ConnectionHint::Direct { addr: addr.clone() });
            }
            return hints;
        }
        
        // 2. å¦‚æœåŒæ–¹ NAT å¯ç©¿é€,å°è¯•æ‰“æ´
        if self.can_hole_punch(&requester.nat_type, &target.nat_type) {
            hints.push(ConnectionHint::HolePunching {
                public_addr: target.public_addrs.first().cloned().unwrap(),
                private_addr: target.private_addrs.first().cloned().unwrap(),
                nat_type: target.nat_type,
            });
        }
        
        // 3. å¦åˆ™ä½¿ç”¨ä¸­ç»§
        if let Some(relay) = self.find_relay_node(requester, target).await {
            hints.push(ConnectionHint::Relay {
                relay_node: relay.peer_id,
                relay_addr: relay.public_addrs.first().cloned().unwrap(),
            });
        }
        
        hints
    }
    
    fn can_hole_punch(&self, nat1: &NatType, nat2: &NatType) -> bool {
        match (nat1, nat2) {
            (NatType::Public, _) | (_, NatType::Public) => true,
            (NatType::FullCone, _) | (_, NatType::FullCone) => true,
            (NatType::RestrictedCone, NatType::RestrictedCone) => true,
            (NatType::PortRestricted, NatType::PortRestricted) => true,
            _ => false,  // å¯¹ç§°å‹ NAT éš¾ä»¥ç©¿é€
        }
    }
    
    async fn find_relay_node(
        &self,
        requester: &NodeAddress,
        target: &NodeAddress,
    ) -> Option<NodeAddress> {
        // æŸ¥æ‰¾åŒåŒºåŸŸçš„ L3 èŠ‚ç‚¹ä½œä¸ºä¸­ç»§
        let filter = NodeFilter {
            node_type: Some(NodeType::L3Edge),
            region: Some(requester.region),
            max_latency: Some(50),
            max_load: Some(70),
            min_capability: None,
        };
        
        let l3_nodes = self.routing_table.find_nodes(filter).await;
        l3_nodes.into_iter().next()
    }
}
```

#### 4. NAT ç©¿é€å¢å¼º

```rust
// src/node-core/src/nat_traversal.rs

use stun::client::StunClient;

pub struct NatTraversalService {
    local_addr: SocketAddr,
    stun_servers: Vec<String>,
}

impl NatTraversalService {
    /// æ£€æµ‹ NAT ç±»å‹
    pub async fn detect_nat_type(&self) -> Result<NatType> {
        // 1. ä½¿ç”¨ STUN åè®®æ£€æµ‹
        let stun_client = StunClient::new(self.stun_servers[0].clone());
        
        // æµ‹è¯• 1: è·å–å…¬ç½‘åœ°å€
        let public_addr = stun_client.get_mapped_address().await?;
        
        if public_addr.ip() == self.local_addr.ip() {
            return Ok(NatType::Public);  // å…¬ç½‘ IP
        }
        
        // æµ‹è¯• 2: ä¸åŒ STUN æœåŠ¡å™¨è¿”å›çš„åœ°å€æ˜¯å¦ä¸€è‡´
        let public_addr2 = StunClient::new(self.stun_servers[1].clone())
            .get_mapped_address()
            .await?;
        
        if public_addr != public_addr2 {
            return Ok(NatType::Symmetric);  // å¯¹ç§°å‹ NAT
        }
        
        // æµ‹è¯• 3: å°è¯•ä»ä¸åŒç«¯å£è¿æ¥
        // ...æ›´å¤šæ£€æµ‹é€»è¾‘
        
        Ok(NatType::FullCone)
    }
    
    /// ICE åè®®æ‰“æ´
    pub async fn ice_hole_punch(
        &self,
        target: &NodeAddress,
        relay: Option<NodeAddress>,
    ) -> Result<Connection> {
        // 1. æ”¶é›†å€™é€‰åœ°å€ (ICE Candidates)
        let mut candidates = Vec::new();
        
        // 1.1 Host candidate (æœ¬åœ°åœ°å€)
        candidates.push(Candidate::Host(self.local_addr));
        
        // 1.2 Server reflexive candidate (STUN åœ°å€)
        if let Ok(public_addr) = self.stun_discovery().await {
            candidates.push(Candidate::ServerReflexive(public_addr));
        }
        
        // 1.3 Relay candidate (TURN åœ°å€)
        if let Some(relay_node) = relay {
            if let Ok(relay_addr) = self.turn_allocate(&relay_node).await {
                candidates.push(Candidate::Relay(relay_addr));
            }
        }
        
        // 2. äº¤æ¢å€™é€‰åœ°å€ (é€šè¿‡ä¿¡ä»¤æœåŠ¡å™¨ or L3 ä¸­ç»§)
        let target_candidates = self.exchange_candidates(target, &candidates).await?;
        
        // 3. è¿æ¥æ€§æ£€æŸ¥ (æŒ‰ä¼˜å…ˆçº§å°è¯•)
        for local in &candidates {
            for remote in &target_candidates {
                if let Ok(conn) = self.try_connect(local, remote).await {
                    return Ok(conn);
                }
            }
        }
        
        Err(anyhow!("NAT traversal failed"))
    }
}

#[derive(Debug, Clone)]
pub enum Candidate {
    Host(SocketAddr),              // æœ¬åœ°åœ°å€
    ServerReflexive(SocketAddr),   // STUN æ˜ å°„åœ°å€
    Relay(SocketAddr),             // TURN ä¸­ç»§åœ°å€
}
```

#### 5. å®æ—¶å¯»å€æ€§èƒ½

```rust
// æ€§èƒ½æŒ‡æ ‡

pub struct AddressingMetrics {
    /// å¹³å‡æŸ¥è¯¢å»¶è¿Ÿ
    pub avg_lookup_latency: Duration,
    
    /// ç¼“å­˜å‘½ä¸­ç‡
    pub cache_hit_rate: f64,
    
    /// NAT ç©¿é€æˆåŠŸç‡
    pub nat_success_rate: f64,
    
    /// ä¸­ç»§ä½¿ç”¨ç‡
    pub relay_usage_rate: f64,
    
    /// L4 å‚ä¸åº¦ (å¯ç”¨è·¯ç”±ä¸­ç»§çš„ L4 èŠ‚ç‚¹æ¯”ä¾‹)
    pub l4_participation_rate: f64,
}

// é¢„æœŸæ€§èƒ½:
// 
// L4 â†’ L4 æŸ¥è¯¢: < 5 ms (æœ¬åœ°ç¼“å­˜/åŒå±€åŸŸç½‘ P2P) â­ æ–°å¢
// L4 â†’ L3 æŸ¥è¯¢: < 10 ms (åŒåŒºåŸŸç¼“å­˜å‘½ä¸­)
// L4 â†’ L2 æŸ¥è¯¢: < 50 ms (è·¨åŒºåŸŸæŸ¥è¯¢)
// L4 â†’ L1 æŸ¥è¯¢: < 100 ms (å…¨å±€æŸ¥è¯¢)
// 
// ç¼“å­˜å‘½ä¸­ç‡:
// L4: 30-40% (æœ¬åœ°çƒ­ç‚¹,å¸¸ç”¨è”ç³»äºº) â­ æ–°å¢
// L3: 80-90% (åŒºåŸŸçƒ­ç‚¹)
// L2: 60-70% (å…¨å±€çƒ­ç‚¹)
// L1: 100% (æƒå¨æ•°æ®)
// 
// NAT ç©¿é€æˆåŠŸç‡:
// æ— ååŠ©: 70-80%
// æœ‰ L4 ååŠ©: 85-90% â­ æ–°å¢
// æœ‰ L3 ä¸­ç»§: 95%+
// 
// è¿æ¥å»ºç«‹æ—¶é—´:
// L4 P2Pç›´è¿: < 50 ms (åŒå±€åŸŸç½‘) â­ æ–°å¢
// ç›´è¿: < 100 ms
// æ‰“æ´: < 500 ms
// ä¸­ç»§: < 200 ms
// 
// L4 å‚ä¸åº¦:
// é«˜å†…å­˜è®¾å¤‡ (>4GB): 50-70% å¯ç”¨è·¯ç”±ä¸­ç»§
// ä¸­ç­‰è®¾å¤‡ (2-4GB): 20-30% å¯ç”¨è·¯ç”±ä¸­ç»§
// ä½å†…å­˜è®¾å¤‡ (<2GB): 5-10% å¯ç”¨è·¯ç”±ä¸­ç»§
```

#### 6. L4 èŠ‚ç‚¹å‚ä¸è·¯ç”±çš„åˆ›æ–°è®¾è®¡ â­ **æ ¸å¿ƒåˆ›æ–°**

##### è®¾è®¡ç†å¿µ: "äººäººä¸ºæˆ‘,æˆ‘ä¸ºäººäºº"

```
ä¼ ç»Ÿ P2P ç½‘ç»œ:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è½»èŠ‚ç‚¹ â†’ å®Œå…¨ä¾èµ–å¼ºèŠ‚ç‚¹ (DHT/ä¸­ç»§)
âŒ è½»èŠ‚ç‚¹æ˜¯"å¯„ç”Ÿè€…",æ¶ˆè€—èµ„æºä½†ä¸è´¡çŒ®
âŒ å¼ºèŠ‚ç‚¹è´Ÿè½½è¿‡é‡,å®¹æ˜“æˆä¸ºç“¶é¢ˆ
âŒ ç½‘ç»œæ‰©å±•æ€§å·® (è½»èŠ‚ç‚¹è¶Šå¤š,è´Ÿè½½è¶Šé‡)

SuperVM å››å±‚ååŒç½‘ç»œ:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
L4 è½»èŠ‚ç‚¹ â†’ æ ¹æ®èƒ½åŠ›è´¡çŒ®è·¯ç”±æœåŠ¡
âœ… L4 èŠ‚ç‚¹ä¹Ÿæ˜¯"è´¡çŒ®è€…",ç¼“å­˜å¸¸ç”¨èŠ‚ç‚¹
âœ… L4 ä¹‹é—´å¯ä»¥ P2P äº’åŠ© (å‡è½» L3 è´Ÿè½½)
âœ… ç½‘ç»œæ‰©å±•æ€§å¥½ (èŠ‚ç‚¹è¶Šå¤š,è·¯ç”±è¶Šå¿«)
âœ… å±€åŸŸç½‘ä¼˜åŒ– (WiFi/è“ç‰™å‘ç°,å»¶è¿Ÿ < 5ms)
```

##### ä¸‰çº§å‚ä¸æ¨¡å¼

```rust
// L4 èŠ‚ç‚¹æ ¹æ®ç¡¬ä»¶èƒ½åŠ›å’Œä½¿ç”¨æƒ…å†µ,è‡ªåŠ¨é€‰æ‹©å‚ä¸çº§åˆ«

pub enum L4ParticipationLevel {
    /// è¢«åŠ¨æ¨¡å¼ (åªæ¶ˆè´¹,ä¸è´¡çŒ®)
    /// - ä½å†…å­˜è®¾å¤‡ (<1GB)
    /// - çœç”µæ¨¡å¼
    /// - æµé‡å—é™
    Passive {
        cache_size: 50,           // æœ€å°ç¼“å­˜
        relay: false,             // ä¸æä¾›ä¸­ç»§
        nat_assist: false,        // ä¸ååŠ©ç©¿é€
    },
    
    /// æ ‡å‡†æ¨¡å¼ (é€‚åº¦å‚ä¸)
    /// - ä¸­ç­‰è®¾å¤‡ (2-4GB)
    /// - æ­£å¸¸ä½¿ç”¨
    Standard {
        cache_size: 100-200,      // ä¸­ç­‰ç¼“å­˜
        relay: true,              // å¯ç”¨è·¯ç”±ä¸­ç»§ (å¦‚å‘½ä¸­ç‡>50%)
        nat_assist: true,         // ååŠ© NAT ç©¿é€
        local_discovery: true,    // æœ¬åœ°å‘ç° (WiFi/è“ç‰™)
    },
    
    /// ç§¯ææ¨¡å¼ (ä¸»åŠ¨è´¡çŒ®)
    /// - é«˜ç«¯è®¾å¤‡ (>4GB)
    /// - WiFi/å……ç”µä¸­
    /// - æ— æµé‡é™åˆ¶
    Active {
        cache_size: 300-500,      // å¤§å®¹é‡ç¼“å­˜
        relay: true,              // å¼ºåˆ¶å¯ç”¨ä¸­ç»§
        nat_assist: true,         // ç§¯æååŠ©ç©¿é€
        local_discovery: true,    // æœ¬åœ°å‘ç°
        preload: true,            // é¢„åŠ è½½çƒ­é—¨èŠ‚ç‚¹
    },
}
```

##### L4 æœ¬åœ°ç½‘ç»œååŒ

```
åœºæ™¯ 1: åŒä¸€ WiFi ç½‘ç»œä¸‹çš„å¤šä¸ª L4 è®¾å¤‡
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[æ‰‹æœºA] â”€â”€â”
          â”œâ”€â†’ [æœ¬åœ° mDNS å‘ç°] â”€â”€â†’ å»¶è¿Ÿ < 5 ms
[æ‰‹æœºB] â”€â”€â”¤                          ä¸æ¶ˆè€—æµé‡
          â”‚                          ä¸é€šè¿‡ L3
[å¹³æ¿C] â”€â”€â”˜

ä¼˜åŠ¿:
âœ… å»¶è¿Ÿæä½ (< 5 ms, æœ¬åœ°å±€åŸŸç½‘)
âœ… é›¶æµé‡æ¶ˆè€— (WiFi å†…ç½‘é€šä¿¡)
âœ… å‡è½» L3 è´Ÿè½½ (ä¸éœ€è¦ä¸Šä¼ æŸ¥è¯¢)
âœ… éšç§å¢å¼º (ä¸æš´éœ²ç»™ä¸Šæ¸¸èŠ‚ç‚¹)

åœºæ™¯ 2: è“ç‰™è¿‘è·ç¦»å‘ç°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[æ‰‹æœºA] <â”€â”€â”€ è“ç‰™ (10ç±³èŒƒå›´) â”€â”€â”€> [æ‰‹æœºB]

é€‚ç”¨åœºæ™¯:
- çº¿ä¸‹æ”¯ä»˜/è½¬è´¦ (é¢å¯¹é¢äº¤æ˜“)
- æ¸¸æˆç»„é˜Ÿ (æœ¬åœ°å¤šäººæ¸¸æˆ)
- æ–‡ä»¶åˆ†äº« (ç‚¹å¯¹ç‚¹ä¼ è¾“)

ä¼˜åŠ¿:
âœ… æ— éœ€ç½‘ç»œ (ç¦»çº¿å¯ç”¨)
âœ… é›¶æµé‡
âœ… éšç§æœ€ä½³ (å®Œå…¨ç‚¹å¯¹ç‚¹)

åœºæ™¯ 3: L4 ä¹‹é—´çš„è·¯ç”±äº’åŠ©
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[æ‰‹æœºA] éœ€è¦è¿æ¥ [æ‰‹æœºX]
   â†“
æŸ¥è¯¢æœ¬åœ°ç¼“å­˜ â†’ æœªæ‰¾åˆ°
   â†“
æŸ¥è¯¢åŒå±€åŸŸç½‘çš„ [æ‰‹æœºB] â†’ [æ‰‹æœºB] ç¼“å­˜å‘½ä¸­! è¿”å› [æ‰‹æœºX] åœ°å€
   â†“
[æ‰‹æœºA] ç›´æ¥è¿æ¥ [æ‰‹æœºX]

æ•ˆæœ:
- [æ‰‹æœºA] ä¸éœ€è¦æŸ¥è¯¢ L3 (èŠ‚çœ 10ms + æµé‡)
- [æ‰‹æœºB] ç¼“å­˜è¢«åˆ©ç”¨ (èµ„æºä¸æµªè´¹)
- ç½‘ç»œæ•´ä½“è´Ÿè½½é™ä½
```

##### L4 NAT ç©¿é€äº’åŠ©

```rust
// åœºæ™¯: L4-A éœ€è¦è¿æ¥ L4-B, ä½†éƒ½åœ¨ NAT åé¢

pub async fn l4_assisted_nat_traversal(
    node_a: &L4Node,
    node_b: &L4Node,
    assistant: &L4Node,  // ç¬¬ä¸‰æ–¹ L4 èŠ‚ç‚¹ååŠ©
) -> Result<Connection> {
    // 1. L4-Assistant å……å½“ STUN æœåŠ¡å™¨
    let a_public = assistant.detect_peer_address(node_a).await?;
    let b_public = assistant.detect_peer_address(node_b).await?;
    
    // 2. L4-Assistant å‘Šè¯‰åŒæ–¹å¯¹æ–¹çš„å…¬ç½‘åœ°å€
    assistant.send_stun_info(node_a, b_public).await?;
    assistant.send_stun_info(node_b, a_public).await?;
    
    // 3. L4-A å’Œ L4-B åŒæ—¶å‘å¯¹æ–¹å‘èµ·è¿æ¥ (æ‰“æ´)
    let conn = tokio::try_join!(
        node_a.punch_hole(b_public),
        node_b.punch_hole(a_public),
    )?;
    
    Ok(conn.0)  // è¿”å›æˆåŠŸå»ºç«‹çš„è¿æ¥
}

// ä¼˜åŠ¿:
// - ä¸éœ€è¦ L3 å‚ä¸ (å‡è½» L3 è´Ÿè½½)
// - æˆåŠŸç‡æå‡: 70% â†’ 85% (L4 ååŠ©)
// - å»¶è¿Ÿæ›´ä½ (L4 é€šå¸¸åœ¨åŒåŒºåŸŸ)
```

##### è‡ªåŠ¨èƒ½åŠ›æ£€æµ‹ä¸å‡çº§

```rust
// L4 èŠ‚ç‚¹è‡ªåŠ¨ç›‘æ§è‡ªå·±çš„ä½¿ç”¨æƒ…å†µ,å†³å®šæ˜¯å¦å‡çº§å‚ä¸çº§åˆ«

impl L4Node {
    pub async fn auto_adjust_participation(&mut self) -> Result<()> {
        let stats = self.routing_table.query_stats.lock().await;
        
        // æ¡ä»¶ 1: è¢«è¯·æ±‚æ¬¡æ•°å¤š â†’ è¯´æ˜å…¶ä»–èŠ‚ç‚¹éœ€è¦æˆ‘çš„å¸®åŠ©
        let high_demand = stats.request_count > 100;
        
        // æ¡ä»¶ 2: ç¼“å­˜å‘½ä¸­ç‡é«˜ â†’ è¯´æ˜æˆ‘çš„ç¼“å­˜æœ‰ä»·å€¼
        let high_hit_rate = stats.cache_hit_count as f64 / stats.request_count as f64 > 0.5;
        
        // æ¡ä»¶ 3: è®¾å¤‡çŠ¶æ€è‰¯å¥½
        let good_battery = self.battery_level > 50;
        let on_wifi = self.network_type == NetworkType::WiFi;
        let available_memory = self.available_memory_mb() > 1024;
        
        // å†³ç­–: æ˜¯å¦å‡çº§ä¸ºç§¯ææ¨¡å¼
        if high_demand && high_hit_rate && good_battery && on_wifi && available_memory {
            self.participation_level = L4ParticipationLevel::Active {
                cache_size: 500,
                relay: true,
                nat_assist: true,
                local_discovery: true,
                preload: true,
            };
            
            info!("L4 èŠ‚ç‚¹å‡çº§ä¸ºç§¯ææ¨¡å¼,å¼€å§‹ä¸»åŠ¨è´¡çŒ®è·¯ç”±æœåŠ¡");
            
            // é¢„åŠ è½½çƒ­é—¨èŠ‚ç‚¹
            self.preload_popular_nodes().await?;
        }
        
        Ok(())
    }
}

### å…³é”®ä¼˜åŠ¿

#### 1. **ç±» DNS çš„åˆ†å±‚ç¼“å­˜**

```
æŸ¥è¯¢è·¯å¾„:
L4 å®¢æˆ·ç«¯ â†’ L3 (ç¼“å­˜ 80% å‘½ä¸­) â†’ L2 (ç¼“å­˜ 60% å‘½ä¸­) â†’ L1 (æƒå¨)

å¹³å‡æŸ¥è¯¢å»¶è¿Ÿ:
- 80% è¯·æ±‚åœ¨ L3 å‘½ä¸­: < 10 ms
- 15% è¯·æ±‚åœ¨ L2 å‘½ä¸­: < 50 ms
- 5% è¯·æ±‚åœ¨ L1 æŸ¥è¯¢: < 100 ms

åŠ æƒå¹³å‡: 0.8Ã—10 + 0.15Ã—50 + 0.05Ã—100 = 20.5 ms
```

#### 2. **èƒ½åŠ›æ„ŸçŸ¥è·¯ç”±**

```rust
// æ ¹æ®ä»»åŠ¡è‡ªåŠ¨é€‰æ‹©æœ€ä½³èŠ‚ç‚¹

Task::ZkProof(_) 
  â†’ æŸ¥è¯¢: node_type=L1, has_gpu=true, region=nearest
  â†’ è¿”å›: æœ€è¿‘çš„å¸¦ GPU çš„ L1 èŠ‚ç‚¹

Task::Query(_)
  â†’ æŸ¥è¯¢: node_type=L3, region=same, max_latency=20ms
  â†’ è¿”å›: åŒåŒºåŸŸçš„ L3 è¾¹ç¼˜èŠ‚ç‚¹

Task::TxExecution(_)
  â†’ æŸ¥è¯¢: node_type=L2, max_load=70, region=nearest
  â†’ è¿”å›: è´Ÿè½½æœ€ä½çš„ L2 çŸ¿æœºèŠ‚ç‚¹
```

#### 3. **æ™ºèƒ½ NAT ç©¿é€ (å¤šçº§ååŠ©)**

```
ä¼ ç»Ÿ P2P (STUN/TURN):
æˆåŠŸç‡: 60-70%
å»¶è¿Ÿ: é«˜ (éœ€è¦å¤šæ¬¡å°è¯•)
æˆæœ¬: é«˜ (éœ€è¦ä¸“ç”¨ TURN æœåŠ¡å™¨)

SuperVM (å¤šçº§ååŠ©):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Level 1: L4 äº’åŠ©ç©¿é€ (æˆåŠŸç‡ 85%) â­ æ–°å¢
  - L4 èŠ‚ç‚¹å……å½“ STUN æœåŠ¡å™¨
  - é€‚ç”¨äº: ä¸¤ä¸ª L4 èŠ‚ç‚¹è¿æ¥
  - å»¶è¿Ÿ: < 300 ms
  - æˆæœ¬: é›¶ (P2P äº’åŠ©)

Level 2: L3 ä¸­ç»§è¾…åŠ© (æˆåŠŸç‡ 95%)
  - L3 èŠ‚ç‚¹å……å½“ä¸­ç»§
  - é€‚ç”¨äº: L4-L2 è¿æ¥, æˆ– L4-L4 ç©¿é€å¤±è´¥
  - å»¶è¿Ÿ: < 500 ms
  - æˆæœ¬: ä½ (åˆ©ç”¨ç°æœ‰ L3 èŠ‚ç‚¹)

Level 3: L1 å¼ºåˆ¶ä¸­ç»§ (æˆåŠŸç‡ 100%)
  - L1 èŠ‚ç‚¹å……å½“ä¸­ç»§ (å…¬ç½‘ IP)
  - é€‚ç”¨äº: æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
  - å»¶è¿Ÿ: < 1000 ms
  - æˆæœ¬: ä¸­ (L1 èµ„æºå®è´µ)

ä¼˜åŠ¿:
âœ… å¤šçº§ fallback,æˆåŠŸç‡æ¥è¿‘ 100%
âœ… ä¼˜å…ˆä½¿ç”¨ L4 äº’åŠ© (é›¶æˆæœ¬)
âœ… å¤±è´¥è‡ªåŠ¨å‡çº§åˆ°æ›´å¼ºèŠ‚ç‚¹
âœ… è¿æ¥å»ºç«‹åå¯å‡çº§ä¸ºç›´è¿
```

#### 4. **L4 å…¨å‘˜å‚ä¸,ç½‘ç»œè‡ªæ„ˆ** â­ **æ ¸å¿ƒåˆ›æ–°**

```
ä¼ ç»Ÿæ¨¡å¼:
è½»èŠ‚ç‚¹ (æ¶ˆè´¹) â”€â”€â†’ å¼ºèŠ‚ç‚¹ (æä¾›)
- è½»èŠ‚ç‚¹è¶Šå¤š,å¼ºèŠ‚ç‚¹è¶Šç´¯
- ç½‘ç»œæ‰©å±•æ€§å·®
- å•ç‚¹ç“¶é¢ˆé£é™©é«˜

SuperVM æ¨¡å¼:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ¯ä¸ªèŠ‚ç‚¹æ—¢æ˜¯æ¶ˆè´¹è€…,ä¹Ÿæ˜¯è´¡çŒ®è€…

[L4-A] â†â†’ [L4-B]  (P2P äº’åŠ©)
  â†‘         â†‘
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
        â†“
      [L3]  (ä»…å¤„ç† L4 æ— æ³•è§£å†³çš„æŸ¥è¯¢)
        â†“
      [L2]  (å¤„ç†è·¨åŒºåŸŸæŸ¥è¯¢)
        â†“
      [L1]  (æƒå¨è·¯ç”±è¡¨)

æ•ˆæœ:
âœ… 70% çš„ L4-L4 æŸ¥è¯¢åœ¨ L4 å±‚è§£å†³ (ä¸æ¶ˆè€— L3)
âœ… èŠ‚ç‚¹è¶Šå¤š,ç½‘ç»œè¶Šå¿« (ç¼“å­˜å‘½ä¸­ç‡æå‡)
âœ… è‡ªæ„ˆèƒ½åŠ›å¼º (L4 å¯ä»¥äº’ç›¸å¤‡ä»½)
âœ… æˆæœ¬åˆ†æ‘Š (æ¯ä¸ªèŠ‚ç‚¹è´¡çŒ®ä¸€ç‚¹,æ•´ä½“æ”¶ç›Šå¤§)

æ•°æ®:
- 1000 ä¸ª L4 èŠ‚ç‚¹,50% å¯ç”¨ä¸­ç»§
- å¹³å‡æ¯ä¸ª L4 ç¼“å­˜ 200 èŠ‚ç‚¹
- ç†è®ºè·¯ç”±å®¹é‡: 1000 Ã— 200 Ã— 0.5 = 100K èŠ‚ç‚¹ä¿¡æ¯
- å®é™…å¯æœåŠ¡: 10M+ L4 èŠ‚ç‚¹ (è€ƒè™‘ç¼“å­˜é‡å )
```

#### 5. **å®æ—¶è´Ÿè½½æ„ŸçŸ¥**

```rust
// æ¯ä¸ªèŠ‚ç‚¹å®šæœŸå¿ƒè·³ (10ç§’ä¸€æ¬¡)

impl RoutingTable {
    pub async fn heartbeat_loop(&self) {
        loop {
            // 1. æ”¶é›†æœ¬åœ°è´Ÿè½½
            let metrics = self.collect_metrics();
            
            // 2. æ›´æ–°è·¯ç”±è¡¨
            self.update_local_load(metrics.cpu_usage).await;
            
            // 3. å¹¿æ’­åˆ°ä¸Šæ¸¸ (L4â†’L3, L3â†’L2, L2â†’L1)
            self.broadcast_heartbeat(metrics).await;

#### 4. **å®æ—¶è´Ÿè½½æ„ŸçŸ¥**

```rust
// æ¯ä¸ªèŠ‚ç‚¹å®šæœŸå¿ƒè·³ (10ç§’ä¸€æ¬¡)

impl RoutingTable {
    pub async fn heartbeat_loop(&self) {
        loop {
            // 1. æ”¶é›†æœ¬åœ°è´Ÿè½½
            let metrics = self.collect_metrics();
            
            // 2. æ›´æ–°è·¯ç”±è¡¨
            self.update_local_load(metrics.cpu_usage).await;
            
            // 3. å¹¿æ’­åˆ°ä¸Šæ¸¸ (L4â†’L3, L3â†’L2, L2â†’L1)
            self.broadcast_heartbeat(metrics).await;
            
            tokio::time::sleep(Duration::from_secs(10)).await;
        }
    }
}

// æ•ˆæœ:
// - è¿‡è½½èŠ‚ç‚¹è‡ªåŠ¨ä»è·¯ç”±è¡¨é™æƒ
// - æ–°èŠ‚ç‚¹å¿«é€ŸåŠ å…¥è·¯ç”±è¡¨
// - ä¸‹çº¿èŠ‚ç‚¹å¿«é€Ÿæ¸…é™¤
```

### å®æ–½è®¡åˆ’

åœ¨ **Phase 6.4: P2P ç½‘ç»œä¸é€šä¿¡ (3 å‘¨)** ä¸­å®ç°:

**Week 1: åŸºç¡€å¯»å€ç³»ç»Ÿ**
- [ ] å®ç° `NodeAddress` å’Œåœ°å€ç³»ç»Ÿ
- [ ] å®ç°å››å±‚è·¯ç”±è¡¨ (L1/L2/L3/L4)
- [ ] å®ç° `AddressingService` æŸ¥è¯¢åè®®
- [ ] NAT ç±»å‹æ£€æµ‹ (STUN)

**Week 2: æ™ºèƒ½è·¯ç”±ä¸ç©¿é€**
- [ ] å®ç°æ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©ç®—æ³•
- [ ] å®ç° ICE åè®®æ‰“æ´
- [ ] å®ç° L3 ä¸­ç»§æœåŠ¡
- [ ] å®ç°è¿æ¥æç¤ºç”Ÿæˆ

**Week 3: ä¼˜åŒ–ä¸æµ‹è¯•**
- [ ] ç¼“å­˜ä¼˜åŒ– (LRU + é¢„å–)
- [ ] å¿ƒè·³æœºåˆ¶å’Œè´Ÿè½½æ›´æ–°
- [ ] NAT ç©¿é€æˆåŠŸç‡æµ‹è¯•
- [ ] å¯»å€å»¶è¿ŸåŸºå‡†æµ‹è¯•
- [ ] è·¨åŒºåŸŸè¿æ¥æµ‹è¯•

### æŠ€æœ¯æ ˆ

```rust
// ä¾èµ– crates

[dependencies]
libp2p = { version = "0.53", features = [
    "kad",           // Kademlia DHT
    "mdns",          // æœ¬åœ°ç½‘ç»œå‘ç°
    "relay",         // ä¸­ç»§åè®®
    "dcutr",         // ç›´è¿å‡çº§
    "noise",         // åŠ å¯†
    "yamux",         // å¤šè·¯å¤ç”¨
] }

stun = "0.5"         // STUN åè®® (NAT æ£€æµ‹)
ice = "0.9"          // ICE åè®® (æ‰“æ´)
lru = "0.12"         // LRU ç¼“å­˜
dashmap = "5.5"      // å¹¶å‘å“ˆå¸Œè¡¨
bincode = "1.3"      // åºåˆ—åŒ–
```

### å¯¹æ¯”ä¼ ç»Ÿæ–¹æ¡ˆ

| ç‰¹æ€§ | ä¼ ç»Ÿ P2P (DHT) | SuperVM ç¥ç»ç½‘ç»œå¯»å€ (å®Œæ•´) |
|------|---------------|---------------------------|
| **æŸ¥è¯¢å»¶è¿Ÿ** | 100-500 ms (å¤šè·³) | **5-50 ms** (L4 P2P: 5ms, L3: 10ms) â­ |
| **ç¼“å­˜å‘½ä¸­ç‡** | æ—  | **L4: 30-40%, L3: 80-90%** â­ |
| **è½»èŠ‚ç‚¹å‚ä¸** | å¦ (ä»…æ¶ˆè´¹) | **æ˜¯ (50-70% L4 è´¡çŒ®è·¯ç”±)** â­ |
| **èƒ½åŠ›æ„ŸçŸ¥** | å¦ | æ˜¯ (ç¡¬ä»¶/è´Ÿè½½/NAT) |
| **æ™ºèƒ½è·¯ç”±** | å¦ | æ˜¯ (ä»»åŠ¡åŒ¹é…) |
| **NAT ç©¿é€** | 60-70% | **85% (L4), 95%+ (L3)** â­ |
| **è´Ÿè½½å‡è¡¡** | éšæœº | æ™ºèƒ½ (å»¶è¿Ÿ+è´Ÿè½½) |
| **åŒºåŸŸä¼˜åŒ–** | å¦ | æ˜¯ (å°±è¿‘æœåŠ¡) |
| **æœ¬åœ°å‘ç°** | å¦ | **æ˜¯ (WiFi/è“ç‰™ < 5ms)** â­ |
| **ç¦»çº¿å¯ç”¨** | å¦ | **éƒ¨åˆ† (è“ç‰™ P2P)** â­ |
| **ç½‘ç»œæ‰©å±•æ€§** | å·® (èŠ‚ç‚¹å¤šè´Ÿè½½é‡) | **å¥½ (èŠ‚ç‚¹å¤šè·¯ç”±å¿«)** â­ |
| **ä¸­ç»§æˆæœ¬** | é«˜ (ä¸“ç”¨ TURN) | **ä½ (P2P äº’åŠ©)** â­ |

---

## ğŸ—ºï¸ å®æ–½è·¯çº¿å›¾

### Phase 6.1: å››å±‚ç½‘ç»œåŸºç¡€æ¡†æ¶ (4 å‘¨)

**Week 1: ç¡¬ä»¶æ£€æµ‹ä¸èŠ‚ç‚¹ç±»å‹å†³ç­–**
- [ ] å®ç° `HardwareDetector`
- [ ] å®ç° `NodeType::auto_detect()`
- [ ] åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿ (L1/L2/L3/L4)
- [ ] å®ç°å‘½ä»¤è¡Œå‚æ•°è§£æ

**Week 2: ä»»åŠ¡è·¯ç”±ä¸åˆ†å‘**
- [ ] å®ç° `TaskRouter`
- [ ] å®šä¹‰ `Task` æšä¸¾å’Œå±æ€§
- [ ] å®ç°ä»»åŠ¡å¤æ‚åº¦è¯„ä¼°
- [ ] å®ç°ä»»åŠ¡è·¯ç”±å†³ç­–æ ‘

**Week 3: è´Ÿè½½å‡è¡¡ä¸è°ƒåº¦**
- [ ] å®ç° `LoadBalancer`
- [ ] å®ç°èŠ‚ç‚¹å¾—åˆ†ç®—æ³•
- [ ] å®ç°å¿ƒè·³å’Œå¥åº·æ£€æŸ¥
- [ ] å®ç°åŠ¨æ€è´Ÿè½½è°ƒæ•´

**Week 4: æµ‹è¯•ä¸æ–‡æ¡£**
- [ ] å•å…ƒæµ‹è¯• (è¦†ç›–ç‡ > 80%)
- [ ] é›†æˆæµ‹è¯• (4 å±‚ç½‘ç»œæ¨¡æ‹Ÿ)
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] éƒ¨ç½²æ–‡æ¡£å’Œç”¨æˆ·æŒ‡å—

### Phase 6.2: å­˜å‚¨åˆ†å±‚ç®¡ç† (3 å‘¨)

**Week 1: L1/L2 å­˜å‚¨å®ç°**
- [ ] L1 RocksDB å®Œæ•´çŠ¶æ€
- [ ] L2 RocksDB è£å‰ªç­–ç•¥
- [ ] çŠ¶æ€åŒæ­¥åè®® (L2â†’L1)
- [ ] åŒºå—å½’æ¡£æœºåˆ¶

**Week 2: L3/L4 ç¼“å­˜å®ç°**
- [ ] L3 LRU ç¼“å­˜
- [ ] L3 é¢„å–ç­–ç•¥
- [ ] L4 SQLite è½»é‡å­˜å‚¨
- [ ] çŠ¶æ€åŒæ­¥åè®® (L4â†’L3, L3â†’L2)

**Week 3: æµ‹è¯•ä¸ä¼˜åŒ–**
- [ ] å­˜å‚¨æ€§èƒ½æµ‹è¯•
- [ ] ç¼“å­˜å‘½ä¸­ç‡æµ‹è¯•
- [ ] æ•°æ®ä¸€è‡´æ€§æµ‹è¯•
- [ ] åŒæ­¥å»¶è¿Ÿæµ‹è¯•

### Phase 6.3: ç®—åŠ›æ± ä¸åˆ†å¸ƒå¼è®¡ç®— (4 å‘¨)

**Week 1: è®¡ç®—æ± æ¡†æ¶**
- [ ] å®ç° `ComputePool`
- [ ] å®ç° `ComputeNode`
- [ ] ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- [ ] èŠ‚ç‚¹æ³¨å†Œä¸å‘ç°

**Week 2: ä»»åŠ¡è°ƒåº¦**
- [ ] ä»»åŠ¡åˆ†é…ç®—æ³•
- [ ] åˆ†å¸ƒå¼ MapReduce
- [ ] ä»»åŠ¡å¤±è´¥é‡è¯•
- [ ] ç»“æœæ±‡æ€»

**Week 3: GPU åŠ é€Ÿé›†æˆ**
- [ ] ZK è¯æ˜ GPU è°ƒåº¦
- [ ] GPU èŠ‚ç‚¹ç®¡ç†
- [ ] CPU fallback æœºåˆ¶
- [ ] æ‰¹é‡è¯æ˜ä¼˜åŒ–

**Week 4: æµ‹è¯•ä¸ä¼˜åŒ–**
- [ ] ç®—åŠ›æ± æ€§èƒ½æµ‹è¯•
- [ ] åˆ†å¸ƒå¼è®¡ç®—æµ‹è¯•
- [ ] GPU åŠ é€Ÿæ•ˆæœéªŒè¯
- [ ] è´Ÿè½½å‡è¡¡æµ‹è¯•

### Phase 6.4: P2P ç½‘ç»œä¸é€šä¿¡ (3 å‘¨)

**Week 1: ç¥ç»ç½‘ç»œå¯»å€ç³»ç»Ÿ (åŸºç¡€æ¶æ„)** â­ **æ ¸å¿ƒ**
- [ ] å®ç° `NodeAddress` å’Œåœ°å€ç³»ç»Ÿ
  - [ ] `NodeAddress` ç»“æ„ä½“ (PeerId + ç¡¬ä»¶èƒ½åŠ› + NATç±»å‹ + åŒºåŸŸ)
  - [ ] `Region` æšä¸¾å’Œå»¶è¿Ÿä¼°è®¡
  - [ ] `NatType` æ£€æµ‹ (STUN åè®®é›†æˆ)
- [ ] å®ç°å››å±‚è·¯ç”±è¡¨
  - [ ] `L1RootRoutingTable` (RocksDB æŒä¹…åŒ– + å®Œæ•´ç´¢å¼•)
  - [ ] `L2GlobalRoutingTable` (LRU ç¼“å­˜ 10ä¸‡èŠ‚ç‚¹)
  - [ ] `L3RegionalRoutingTable` (åŒºåŸŸç¼“å­˜ 1ä¸‡èŠ‚ç‚¹)
  - [ ] `L4LocalRoutingTable` (æœ¬åœ°ç¼“å­˜ 100èŠ‚ç‚¹)
- [ ] å®ç° `RoutingTable` trait (æ³¨å†Œ/æŸ¥è¯¢/å¿ƒè·³/åˆ é™¤)
- [ ] å•å…ƒæµ‹è¯• (è·¯ç”±è¡¨åŸºæœ¬æ“ä½œ)

**Week 2: æ™ºèƒ½è·¯ç”±ä¸å¿«é€Ÿç©¿é€** â­ **æ ¸å¿ƒ**
- [ ] å®ç° `AddressingService` å¯»å€åè®®
  - [ ] `AddressQuery` æŸ¥è¯¢è¯·æ±‚ (æ”¯æŒè¿‡æ»¤æ¡ä»¶)
  - [ ] `AddressResponse` å“åº” (è¿”å›èŠ‚ç‚¹ + è¿æ¥æç¤º)
  - [ ] æ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©ç®—æ³• (å»¶è¿Ÿ + è´Ÿè½½ + èƒ½åŠ›è¯„åˆ†)
- [ ] å®ç° NAT ç©¿é€å¢å¼º
  - [ ] `NatTraversalService` (NAT ç±»å‹æ£€æµ‹)
  - [ ] ICE åè®®æ‰“æ´ (å€™é€‰åœ°å€æ”¶é›† + è¿æ¥æ€§æ£€æŸ¥)
  - [ ] L3 ä¸­ç»§æœåŠ¡ (è‡ªåŠ¨é€‰æ‹©æœ€è¿‘ L3 ä½œä¸º relay)
- [ ] å®ç° `ConnectionHint` ç”Ÿæˆ
  - [ ] ç›´è¿æç¤º (å…¬ç½‘ IP)
  - [ ] æ‰“æ´æç¤º (STUN åœ°å€ + NAT ç±»å‹)
  - [ ] ä¸­ç»§æç¤º (L3 èŠ‚ç‚¹åœ°å€)
- [ ] é›†æˆæµ‹è¯• (ä¸åŒ NAT åœºæ™¯ç©¿é€æµ‹è¯•)

**Week 3: libp2p é›†æˆä¸ä¼˜åŒ–** 
- [ ] libp2p ç½‘ç»œåˆå§‹åŒ– (transport + noise + yamux)
- [ ] èŠ‚ç‚¹å‘ç°ä¼˜åŒ–
  - [ ] mDNS (æœ¬åœ°ç½‘ç»œå¿«é€Ÿå‘ç°)
  - [ ] Kademlia DHT (å…¨å±€å‘ç° + å¤‡ä»½)
  - [ ] ç¥ç»ç½‘ç»œå¯»å€ (ä¸»è¦æ–¹å¼,å–ä»£ä¼ ç»Ÿ DHT)
- [ ] è¿æ¥ç®¡ç†
  - [ ] è¿æ¥æ±  (å¤ç”¨è¿æ¥)
  - [ ] å¿ƒè·³æœºåˆ¶ (10ç§’ä¸€æ¬¡,æ›´æ–°è´Ÿè½½)
  - [ ] è‡ªåŠ¨é‡è¿ (è¿æ¥æ–­å¼€è‡ªåŠ¨æ¢å¤)
- [ ] æ¶ˆæ¯åè®®
  - [ ] Protobuf åºåˆ—åŒ– (å¯»å€æŸ¥è¯¢/å“åº”)
  - [ ] è¯·æ±‚/å“åº”æ¨¡å¼ (RPC)
  - [ ] å‘å¸ƒ/è®¢é˜…æ¨¡å¼ (å¿ƒè·³å¹¿æ’­)
- [ ] æ€§èƒ½æµ‹è¯•ä¸ä¼˜åŒ–
  - [ ] å¯»å€å»¶è¿Ÿæµ‹è¯• (ç›®æ ‡: L3 < 10ms, L2 < 50ms, L1 < 100ms)
  - [ ] ç¼“å­˜å‘½ä¸­ç‡æµ‹è¯• (ç›®æ ‡: L3 80%+, L2 60%+)
  - [ ] NAT ç©¿é€æˆåŠŸç‡æµ‹è¯• (ç›®æ ‡: 95%+)
  - [ ] è·¨åŒºåŸŸè¿æ¥æµ‹è¯• (å…¨çƒèŠ‚ç‚¹æ¨¡æ‹Ÿ)
  - [ ] ç½‘ç»œåˆ†åŒºæ¢å¤æµ‹è¯•
  - [ ] å¸¦å®½ä¼˜åŒ– (å‹ç¼© + æ‰¹é‡ä¼ è¾“)

### Phase 6.5: ç”Ÿäº§éƒ¨ç½² (2 å‘¨)

**Week 1: éƒ¨ç½²å·¥å…·**
- [ ] ä¸€é”®å®‰è£…è„šæœ¬
- [ ] Docker é•œåƒ
- [ ] Kubernetes é…ç½®
- [ ] ç›‘æ§ Dashboard

**Week 2: æ–‡æ¡£ä¸åŸ¹è®­**
- [ ] éƒ¨ç½²æŒ‡å—
- [ ] è¿ç»´æ‰‹å†Œ
- [ ] æ•…éšœæ’æŸ¥
- [ ] ç”¨æˆ·åŸ¹è®­ææ–™

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### æ€§èƒ½æå‡

```
å•æœº SuperVM (å½“å‰):
- TPS: 187K (ä½ç«äº‰)
- æ‰©å±•æ€§: å—é™äºå•æœºç¡¬ä»¶
- æˆæœ¬: é«˜ (éœ€é«˜ç«¯æœåŠ¡å™¨)

å››å±‚ç½‘ç»œ SuperVM (Phase 6 å®Œæˆå):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
L1 (10 èŠ‚ç‚¹):      10-20K TPS Ã— 10  = 100-200K TPS
L2 (100 èŠ‚ç‚¹):     100-200K TPS Ã— 100 = 10-20M TPS
L3 (1000 èŠ‚ç‚¹):    æŸ¥è¯¢å“åº” 1M+ QPS
L4 (æ— é™):         æœ¬åœ°æ“ä½œæ— é™åˆ¶
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ€»ååé‡: 10-20M TPS (ç†è®º)
æŸ¥è¯¢ QPS: 1M+
å…¨çƒå»¶è¿Ÿ: < 100 ms (è·¨æ´²)
           < 10 ms (åŒåŒºåŸŸ)
```

### æˆæœ¬ä¼˜åŒ–

```
ä¼ ç»Ÿæ–¹æ¡ˆ (æ‰€æœ‰èŠ‚ç‚¹é«˜é…):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
100 èŠ‚ç‚¹ Ã— $5000/æœˆ = $500K/æœˆ

å››å±‚ç½‘ç»œæ–¹æ¡ˆ:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
L1 (10 èŠ‚ç‚¹):    $10K/æœˆ Ã— 10  = $100K/æœˆ
L2 (100 èŠ‚ç‚¹):   $2K/æœˆ Ã— 100  = $200K/æœˆ
L3 (1000 èŠ‚ç‚¹):  $100/æœˆ Ã— 1000 = $100K/æœˆ
L4 (ç”¨æˆ·è®¾å¤‡):   $0
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ€»æˆæœ¬: $400K/æœˆ (èŠ‚çœ 20%)
```

### ç®—åŠ›åˆ©ç”¨ç‡

```
ä¼ ç»Ÿæ–¹æ¡ˆ:
- å¹³å‡ç®—åŠ›åˆ©ç”¨ç‡: 30-50%
- å³°å€¼æµªè´¹: 50-70% ç®—åŠ›é—²ç½®

å››å±‚ç½‘ç»œæ–¹æ¡ˆ:
- å¹³å‡ç®—åŠ›åˆ©ç”¨ç‡: 70-90%
- å³°å€¼è°ƒåº¦: åŠ¨æ€å€Ÿç”¨å…¨ç½‘ç®—åŠ›
- ç®—åŠ›å…±äº«: 95%+ åˆ©ç”¨ç‡
```

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

### ç›¸å…³è®¾è®¡æ–‡æ¡£
- [docs/architecture-2.0.md](../architecture-2.0.md) - å®Œæ•´æ¶æ„è®¾è®¡
- [docs/phase1-implementation.md](../phase1-implementation.md) - å®æ–½è®¡åˆ’
- [docs/scenario-analysis-game-defi.md](../scenario-analysis-game-defi.md) - åœºæ™¯åˆ†æ
- [ROADMAP.md Phase 6](../../ROADMAP.md#phase-6-å››å±‚ç¥ç»ç½‘ç»œ) - å¼€å‘è®¡åˆ’

### æŠ€æœ¯å‚è€ƒ
- [Sui Network Architecture](https://docs.sui.io/learn/architecture)
- [Solana Cluster Architecture](https://docs.solana.com/cluster/overview)
- [IPFS Distributed Storage](https://docs.ipfs.io/concepts/)
- [libp2p Networking](https://docs.libp2p.io/)

---

## ğŸ’¡ æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **ä¸€æ ¸å¤šæ€**: åŒä¸€ SuperVM å†…æ ¸,æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨é€‚é… L1/L2/L3/L4
2. **æ™ºèƒ½è·¯ç”±**: ä»»åŠ¡è‡ªåŠ¨è·¯ç”±åˆ°æœ€åˆé€‚çš„èŠ‚ç‚¹æ‰§è¡Œ
3. **å­˜å‚¨åˆ†å±‚**: å®Œæ•´çŠ¶æ€â†’éƒ¨åˆ†çŠ¶æ€â†’çƒ­ç‚¹ç¼“å­˜â†’æœ¬åœ°ç¼“å­˜
4. **ç®—åŠ›æ± åŒ–**: å…¨ç½‘ç®—åŠ›æŒ‰éœ€è°ƒåº¦,å……åˆ†åˆ©ç”¨
5. **è‡ªåŠ¨é™çº§**: ç¡¬ä»¶ä¸è¶³æ—¶è‡ªåŠ¨é™çº§åŠŸèƒ½

### å…³é”®ä¼˜åŠ¿

âœ… **æˆæœ¬ä¼˜åŒ–**: ä¸éœ€è¦æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯é«˜é…  
âœ… **çµæ´»æ‰©å±•**: å¯åŠ¨æ€å¢åŠ å„å±‚èŠ‚ç‚¹  
âœ… **é«˜å¯ç”¨æ€§**: å¤šå±‚å†—ä½™,å•ç‚¹æ•…éšœä¸å½±å“å…¨å±€  
âœ… **å…¨çƒéƒ¨ç½²**: å°±è¿‘æœåŠ¡,é™ä½å»¶è¿Ÿ  
âœ… **ç®—åŠ›å…±äº«**: å……åˆ†åˆ©ç”¨é—²ç½®èµ„æº  

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

```bash
# 1. ç¡¬ä»¶æ£€æµ‹åŸå‹
cargo run --bin hardware-detector

# 2. é…ç½®æ–‡ä»¶ç”Ÿæˆ
./scripts/generate-config.sh --node-type l2

# 3. æœ¬åœ°å››å±‚ç½‘ç»œæ¨¡æ‹Ÿ
docker-compose -f docker/4layer-network.yml up

# 4. æ€§èƒ½åŸºå‡†æµ‹è¯•
cargo bench --bench network_bench
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-11-06  
**ç»´æŠ¤è€…**: KING XU (CHINA)
